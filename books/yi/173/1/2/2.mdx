---
---
---
title: 学习是对领域语法的推理
---




人类的特征之一是不懈地搜寻抽象规则，从一个具体情况及随后在新情况的测试观察中提取出高级别的总结。尝试构建这样的抽象定理可谓非常有力的学习策略，因为大部分抽象定理恰恰就是适用于最多观察的规则。大规模加快学习的终极方法，就是找出能解释所有已知数据的合适定理或逻辑规则，而人脑深谙此道。

我们来看一个例子。想象一打不透光的盒子，里面装满了各种颜色的球。我随机抽选了一个从没有被动过的盒子，伸手进去抽出了一个绿色的球。你能推断盒子里的内容吗？下一个球的颜色会是什么？

第一个进入脑海的答案大概是：我不知道。你没给任何有用信息，我怎么可能知道下一个球的颜色？这可以理解，但是想象一下，我曾从其他盒子里抽取了一些球，你注意到了如下规则：在一个既定盒子里，所有球都是一个颜色。那么这个问题就变得容易了。当我向你展示一个新盒子，你只需要抽出一个绿球就能推断出其余所有球都会是绿色。有了这个普遍规律，仅通过一次测试就能判断结果。

这个例子阐释了高级别知识，常常在所谓的“元”级别中形成，能引导一整个系列的低级别观察。“在一个既定盒子里，所有球的颜色都相同”这一抽象的元规则，一旦被人脑习得，便能大规模地加速学习。当然，它也可能是错的。如果第四个盒子里有所有颜色的球，你会非常震惊（或许我该说“元”震惊）。如果错误发生，你就得修正自己的思维模式，质疑所有盒子都有相同颜色的球的假设。也许你会提出一个更高级别的假设，一个“元-元”假设，比如，你可能会猜测这些盒子有两种：单色的和多色的。这样，要得出任何结论，你就必须至少从每个盒子里抽取两次。在任何情况下，构建一个层级式抽象规则都能帮你省下宝贵的学习时间。

因此，在这一情境下，学习意味着管理内部规则层级，并尝试尽快推导出能归纳整个系列观察的最普遍规则。人脑似乎从儿童时期就开始运用这个层级原则了。就拿一个两三岁的孩子来说，他与父母走在花园里学习新词，比如蝴蝶。通常情况下，只需要听这个词一两次，这个孩子就足以记住它的意思了。这样卓越的学习速度超过了当今任何已知的人工神经网络。这个问题为什么如此困难？因为说出每个词的时候不会完全限制其意义。说出蝴蝶的时候，通常是当一个孩子身处复杂环境中时，周遭是花、树、玩具和人，所有这些因素都是这个词潜在意义的候选项。还有其他较不明显的意义，如我们生活的每个时刻里充斥的声响、味道、活动、行为，还有那些抽象背景。正如我们所知，蝴蝶可以代表颜色、天空、移动或对称性。抽象词汇的存在使这个问题越发令人不解。如果无法感知或体验参照物，那么儿童是如何学习“思考”“相信”“不”“自由”“死亡”这些词的意义的？每当孩子们听到演说者谈到自己用“我”这个字时，他们是如何理解“我”的意思的？

抽象词的快速学习与巴甫洛夫的经典条件反射（Pavlovian conditioning）(5)或斯金纳的操作性条件反射（Skinnerian association）(6)一样，与单词学习的天真观点不相容。仅仅试图将输入与输出、图像与单词联系起来的神经网络，通常需要进行数千次试错，才能开始理解蝴蝶这个词指的是图像角落里的那只颜色鲜艳的昆虫……而这种将单词与图片联系起来的肤浅做法，永远不会发现没有固定参照物的单词的含义，比如“我们”“总是”或“气味”。

词汇习得的机制对认知科学来说是一项巨大挑战。我们知道，解决方案的一部分在于儿童建构非语言的、抽象的、逻辑性的表述能力。甚至在他们学会第一个单词之前，儿童就已经拥有一种思想的语言，他们可以在其中建构并测试抽象的假设。他们的脑不是白板，而他们投射到外部世界的先天知识可以极大地限制他们所处的学习的抽象空间。此外，儿童很快就能学会单词的含义，因为他们在选择假设时，会以一整套高层次的规则作为指导。这种元规则会极大地加速学习，与盒子里的彩色球问题异曲同工。

帮助词汇习得的一个准则在于选择符合数据的最简单、最小的假设（见图2-2）。比如，当一个婴儿听到母亲说“看这只狗”时，理论上，没什么理由会妨碍我们将“狗”这个字指代那只特指的狗（史努比），抑或将其指代任何哺乳动物、有4只脚的生物或活体。儿童如何发现词语的真实意义，比如“狗”代表且只代表所有狗？实验发现，儿童会通过测试所有假设，但只保留符合他们所听到的最简单的那个假设来进行逻辑推理。因此，当儿童听到“史努比”这个词时，他们总是处在这个特定宠物的语境下，符合环境特征的最小范围的假设则局限于这只特定的狗。而且，当儿童第一次听到“狗”这个词时处于单一具体环境中，他们可能暂时会认为这个词只代表了那只特别的动物。但是只要他们在不同环境下再次听到这个词两遍，就能够推断出这个词指代的是狗这整个类别。这个过程的数学模型预测，三四个实例就足够汇聚出一个词的合适意义。13这样的儿童推理比当下的任何人工神经网络都要迅速。

图2-2　脑解释形态的基本原理

学习意味着尝试选择符合数据的最简模型。假设我向你展示a 图并告诉你那3 个被黑色实线包围的物体就是“石灰花”。在缺乏数据的情况下，你怎么找出其他石灰花呢？你的脑会产生一个模型来解释这些形态是怎么产生的，即建一个层级式属性树状图（b图），然后从分支中选择符合数据的最小支。



还有一些其他的诀窍使得儿童比当今人工智能系统能够更快速地学习语言。其中一个元规则是，通常情况下，说话者会专注于自己说话的内容。一旦婴儿理解了这个规律，他们就可以极大地缩小自己搜寻意义的抽象空间。在孩子们获得足够数据证明每当听到“蝴蝶”这个词时都有一种小巧的彩色的昆虫出现以前，他们不必像计算机一般将每个词都与视觉情境中的物体相关联，孩子会随着母亲的视线方向或所指的方向来推断她在说什么。这项语言学习的基本原则被称作“共享关注”（shared attention）。

有一个简单的实验：向一个两三岁的孩子展示一个玩具，然后让一个成人盯着玩具说：“噢，一个沃格（Wog）(7)！”一次实验就可以让这个孩子领会到“沃格”是那个玩具的名字。现在来重复这个情境，但是成人不再说话，而是由一个安装在屋顶的扬声器播放“噢，一个沃格”。孩子在这种情境下基本上学不到任何东西，因为他无法理解说话者的意图。14共享关注这一原则使得孩子学会了抽象概念的全部词汇。这需要他们将自己置身于说话者的视角，去理解说话者指代的具体想法或词语。

儿童还会使用其他许多元规则来学习词语。比如语法背景。当有人对他们说“看那只蝴蝶”时，定冠词“那只（the）”的出现意味着接下来会是一个名词。这也是他们必须学会的元规则。儿童并非生来就知道每门语言的所有冠词，但研究显示他们对这类语言的学习非常迅速。幼儿在12个月大时就已经学会了最常见的定冠词和其他功能性词，并用它们来指导自己后续的学习。15

儿童能做到这一点是因为这些语法词汇频繁出现，且它们几乎是固定出现在名词或名词词组之前。这看起来像循环论证，但并非如此。婴儿从6个月大时开始学习名词，比如最常见的奶瓶和椅子……然后他们会注意到这些词之前有一个常用冠词……他们便推断这些词大概属于同一个类别——名词。这些名词通常又指代物件……当孩子听到一个新读音，比如蝴蝶时，元规则就驱使他们从周围物体中搜寻一个可能的含义，而不是把它当作一个动词或形容词。每个学习情境都在强化这个规则，并推动后续的学习，在每天的大范围实践中加速学习。发展心理学家认为，儿童依赖自举法，通过一系列小型且系统化的推理步骤，逐渐自行发展出语言学习运算能力。

“互排性假设”（mutual exclusivity assumption）是儿童用来加速词汇学习的另一个元规则，被简洁地表述为“一物一名”。这个元规则认为两个不同的词通常不会指代同一个概念，一个新词只能指代一个全新的物体或概念。有了这条规则，儿童只要听到一个不熟悉的词，他们就会限制对自己尚不清楚名字的物体的含义搜索，一般16个月大的儿童就能敏捷地使用这个规则。16试试下面这个实验：拿两个碗，一个是蓝色的，另一个的颜色新颖，比如橄榄绿。要求孩子“给我那个淘滴(8)（towdy）碗”。他通常会给你那个非蓝色的碗，因为他认为如果你说的是蓝色的那个碗，你就会用“蓝色”这个词。既然没用，说明你要的是另一个未知颜色名字的碗。而这一次的经历就足以让他记住这个奇怪的颜色叫做“淘滴”了。

我们再次见证了掌握元规则是如何大规模加速学习的，而这些元规则很有可能是后天习得的。的确，一些实验指出，双语家庭的儿童比单语家庭的儿童更少地使用这些元规则。17双语环境使孩子意识到自己的父母能用不同的词来指代同一件东西。单语家庭的孩子则发现无论父母何时使用新词汇，大概都是想让他们学习一个新物体或概念。如果我们在一个放满类似物件的房间说：“给我这个嘉利士。”孩子们会到处寻找我们说的这件谜一样的东西，而且他们不会认为我们可能指的是一件他们已经知道的东西。

所有这些元规则都阐释了所谓的“抽象之福”（blessing of abstraction）——最抽象的规则是最容易学的，因为儿童听到的每个词语都为之提供了支持证据。因此，类似“名词前一般要加定冠词”的语法规则可能在儿童发展早期就被习得了，并会指导随后的名词词汇的学习。因为抽象之福，儿童在两三岁时会进入一个“词汇爆炸”时期。在这期间，他们能够在只基于有限线索的情况下，每天轻松学会10～20个新词，而这些简单的元规则却正是阻碍机器算法进步的关键。

使用元规则似乎需要足够的智能，但这并非人类物种独有的。从某个程度上来说，其他动物也能进行抽象推理。就拿牧羊犬里克来说，它的训练包括捡起各式各样的物体。18你只需要说：“里克，去捡那个恐龙。”这只动物就会进入游戏房间，几秒后嘴巴里叼着恐龙毛绒玩具回来了。测试他的动物行为学家发现，里克知道大约200个词。最令人振奋的发现是，里克也会使用元规则来学习新词。如果你告诉他：“里克，去捡那个斯克里德（sikirid）(9)。”它总是能叼回一个他不知道名字的新物件。它也会使用“一物一名”这样的元规则。

数学家和计算机科学家已经开始尝试让机器学习层级式规则、元规则和元-元规则，直至任意水平的运算。在这些层级式运算学习中，每一个学习情境不仅会限制低级参数，也会规范高级的抽象参数，从而引导后续的学习。虽然它们的效率尚无法媲美人类的语言学习，但也有了值得赞赏的表现。例如，彩图4显示了最近研发的机器算法如何像寻找外部世界最佳模型的科学家一样行事，19这个系统具有一套抽象原始参数，还有能通过重组基础规则使之制造出无限更高阶结构的语法。比如，它能够将一条线性链定义为一组紧密相连的点，这个定义的特征是“每个点有两个相邻的点，一个在左，一个在右”；这个系统还能够自己去发现这条线性链是代表一组整数（从零到无限）的最佳方式。该语法的一个变形会产生一个二元树状结构，每一个茎节点都有一位家长和两个孩子。这样的树状结构是在当系统被激活时被自动选出来的。这个机器就如人工达尔文一般，会自动自发地去重新发现生命之树！

彩图4

麻省理工学院的两个科学家发明了一种算法，被用来研究科学领域的隐藏性结构。这种算法有个语法规则可以组合出所有新的结构，如线条、平面、圆弧、圆筒……运用这种算法，科学家们论证了动物系统进化树（达尔文）、地球是圆形的〔巴门尼德（Parmenides）〕以及牛顿色环（牛顿）。



组合这些规则还会制造出平面、圆柱体、球体，其算法还能让这些结构符合地球的地理结构。这个算法的升级版本还能表达更抽象的概念。例如，美国计算机科学家诺亚·古德曼（Noah Goodman）和乔希·特南鲍姆（Josh Tenenbaum）设计了一个可以得出因果关系原则的系统。20构建该系统的是一个深奥的数学公式；在一个直接、非循环的联结各个变量的图形中，存在着一个变量子集，其他子集也都依赖于这个子集。这句话很难理解，我引用它是因为这个例子完美描述了这种思维语法所能够表达和测试的一种抽象的内部公式。这个系统会测试上千个公式并保留那些符合输入资料的，从而快速演绎出了因果原则（假如输入的感知经验一部分是原因，而其他的都是结果）。这个例子也论证了抽象之福：这样的高层级假设可以大规模加速学习，因为它将可选假设的搜索范围大幅缩小了。由此，一代又一代的孩子不断地追问着“为什么？”以搜寻可能的解释和原因，这也为人类不断追寻科学知识提供了燃料。

根据这个看法，学习包括从一组众多的人脑思维语言数据中，选出最符合外部事物对应的那一个。我们很快就会看到，这是儿童所拥有的一个卓越模式。他们就像一个个刚出道的科学家，构建理论并将之与外部世界进行比较。这意味着儿童的思维表征比当下的人工神经网络要结构化得多。从出生起，儿童的脑中就已经具备了两个核心成分：能使制造出丰盈的抽象公式成为可能的所有机械装置（即思维语言的组合），以及根据数据的合理性明智选择出合适公式的能力。

这就是脑的新版本21：一个巨大的假设生产模型，制造层级式假设的规则和结构并实现大规模的结构化，同时又能逐渐限制自己以符合现实。