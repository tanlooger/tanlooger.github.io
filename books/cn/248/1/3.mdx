---
---
---
title: 相关性：使用数据的钥匙
---




我们不妨通过下面的例子来说明数据相关性的重要性。

20世纪70年代，中国的国际交往开始恢复正常，为了加快中国的建设，中国政府决定向其他国家就一些重大建设项目进行招标，其中一项是大庆油田石油设备。当时大庆油田的情况中国政府对外保密，西方国家了解甚少，甚至连它的具体地点都不知道。但是来自日本的投标却非常有针对性并且一举中标。其背后的原因是，日本人通过1964年中国的《人民画报》上刊登的铁人王进喜的照片，分析出了关于大庆油田的许多细节

在照片中，王进喜穿着厚棉袄，戴着大皮帽，握着钻井机的扳手眺望远方，背景是高高的井架。在一般人看来，这张照片除了体现出石油工人的豪迈之气，并没有什么特别的地方，但是在日本情报人员看来却披露出许多信息。

首先它泄露了大庆油田的位置。根据王进喜穿的厚棉袄和戴的大皮帽，可以断定油田_定是在中国极北的地区，日本人估计油田应该在哈尔滨和齐齐哈尔之间。其次从背景中井架的密度，大致可以估算出油田的产量。最后从王进喜握手柄的方式，大致能推算出油井的直径。由于日本人获得了关于大庆油田相对准确的信息，因此他们提供的设备非常有针对性，中标也就没有悬念了。



图1.10 1964年《人民画报》上刊登的王进喜的照片

从这个事例中我们可以看出，数据之间常常有我们想象不到的关联性，利用这种关联性，不仅可以获得想要的信息，而且还可能得到意想不到的惊喜。在大数据时代即将到来的时候，一些人敏锐地觉察出了这一点。

2002年年初我到Google面试的时候，面试我的其中一位工程师是阿米特·帕特尔（Amit Patel），他是一位数学博士，考了我一些数学问题，由于我回答得很快，所以剩下很多时间聊一些别的事情。我就问他在Google里面做些什么，通常Google人喜欢故弄玄虚不告诉你他们工作的细节，但是帕特尔倒是挺坦诚。他给我随手画了下面这样一张图。



图1.11 Google用户在不同时间点对某个电视节目的搜索量

他在图中画出的是从Google内部看到的用户在不同时间点对某个电视节目的搜索量。帕特尔问我为什么会出现4个高峰，我说可能是大家在看节目的前后回到Google上搜索这个节目，至于4个高峰，是因为美国跨了4个时区，节目播出的时间各差一个小时。帕特尔同意我这个说法，他又补充道，其实通过它以及各个时区的人口，可以了解到不同电视节目在不同地区（各个时区）的收视率。这样，帕特尔就将搜索量和收视率联系起来了。我称赞他这个发现很有意思，帕特尔感慨道，因为这个工作没有太多经济利益，因此在公司里无法获得多少资源。

几个月后，我加入了Google，发现帕特尔在Google确实不是很受人重视。他加入Google很早，但是人们知道他仅仅是因为他要求和当时新来的CEO（首席执行官）施密特挤一间办公室，而不是他所做的工作。好在Google总是支持每个人干自己所喜欢的事情，因此帕特尔就在Google内部一直研究搜索的模式。

到了2007年，帕特尔突然在全世界声名鹊起，因为他的研究成果被几个工程师开发成了Google的一款产品——Google趋势（Google Trends）。利用这款产品，任何人都可以看到全世界用户在Google上搜索的关键词随着时间和地点变化的趋势，从而知道大家关注什么事情。比如在2015年年底的巴黎气候大会期间，全球范围内“气候变化”（climate change）的搜索量暴增。

当然，如果仅仅是看看搜索趋势的变化，这可能不过是一个小玩具而已。但是，如果把搜索和其他事情关联起来，就能发现非常重要的信息。

2009年，人类发现一种新的流感病毒——甲型H1N1禽流感病毒，短短的一个月内由该病毒导致的疾病就在全球迅速蔓延开来。这让大家想起了1918年欧洲的大流感，当时有5亿人口受到威胁，并且有5000万〜1亿人死亡13，因此甲型H1N1禽流感引起了全世界的恐慌。当时还没有研制出对抗这种流感的疫苗，因此公共卫生专家只能先设法知道这种禽流感流行到了哪里，以便防止它的进一步传播。



图1.12”气候变化”和”全球变暖”在Google上搜索量的变化

数据来源：Google Trends导出数据

过去预报疫情传统的方法是由各地医院、诊所和医务人员向美国疾病控制和预防中心（Centers for Disease Control and Prevention，简称CDC）上报。但是这种方法的延时大约有10天至两周，而两周内疫情早已迅速扩散，因此公共卫生专家需要找到新的办法预测和监控疫情。值得庆幸的是，疾病控制和预防中心的科学家和Google的工程师从2007年到2008年一起合作研究了流行病传播和各地区搜索量变化的关系，并且于2009年2月在著名的《自然》杂志上发表了他们的研究成果14——通过各地区用户在Google上搜索和流感有关的关键词的趋势变化，预测流感流行到什么地方了。Google的工程师们从4.5亿种关键词的组合中，最终挑出45个重要的检索词条和55个次重要词条（归并成12类）作为特征，训练了一个线性回归模型15预测2007年和2008年冬季流感传播的趋势和地点，并且将机器预测的结果和疾病控制与预防中心公布的数据进行比对，发现准确率高达97%以上。

受到这篇论文的启发，疾病控制与预防中心在2009年了解禽流感疫情时采用了同样的方法，获得了更有效、更及时的数据。这个案例后来被各种媒体报道，成为利用大数据解决医疗问题的经典案例。在这个例子中，最关键的是建立起了数据之间的相关性，即疾病传播和该地区搜索关键词变化的关系。

很多时候，我们无法直接获得信息（比如疫情传播情况），但是我们可以将相关联的信息（比如各地搜索情况）量化，然后通过数学模型，间接地得到所要的信息。而各种数学模型的基础都离不开概率论和统计学。