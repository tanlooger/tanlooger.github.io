---
---
---
title: 罗辑思维第780期：为什么说机器只是人的延伸？
---

和你一起终身学习。这里是罗辑思维。

昨天我们讲了一个很离奇的医疗事故。在美国，一个16岁男孩，竟然被医院喂下了高于常规量38.5倍的抗生素，差点丧命。昨天我们已经总结了：是因为机器太能干了，所以制造了空前复杂性；因为机器太可靠了，所以让人放松了警惕；又因为机器太强大了，所以把很小的错误放大成了一场灾难。

看到这件事，很容易得出一个结论，机器不行，安全这事还是得靠人。昨天那个故事里，只要一个大活人，甭管是送药的护士，还是吃药的病人，只要有起码的警觉，多核对一下，不就可以避免悲剧吗？

常识告诉我们，我们生活在一个机器时代。只靠人怕是也不行。今天我们再来看另外一个例子。

2017年的第89届奥斯卡颁奖典礼，闹了一出乌龙事件。把最重头的“最佳影片”奖颁错了。

事情是这样的。当时颁奖嘉宾宣布“最佳影片”是《爱乐之城》。那你想，当然是全场轰动。场外呢，各大媒体几乎同时发了消息，向全球都播发了，主创团队都激动地在台上发表过感言了。结果过了两三分钟，主办方尴尬地宣布，对不起大家，sorry，刚才的奖颁错了，“最佳影片”奖应该是《月光男孩》，不是《爱乐之城》。

你看，这就很尴尬了。

那为什么会出现这个乌龙呢？因为负责递颁奖信封的人把信封拿错了。那这个递信封的人是谁啊？不是普通的阿猫阿狗，是普华永道的审计师。

这件事，说起来有点怪。我们都知道普华永道是全世界最著名的会计师事务所，他们跟奥斯卡颁奖有啥关系？

这段关系由来已久，从1934年就开始了，普华永道为奥斯卡颁奖礼服务已经有80多年的历史了。为啥呢？两个原因。

第一，奥斯卡票数的统计可是个大工程，这本身就是一件非常复杂的会计工作，需要普华永道的专业能力。

但是更重要的，还需要借重普华永道的信用和品牌能力。只有像普华永道这种独立的第三方机构，才能让公众相信这个计票工作即准确又公正，没有黑箱黑幕。那是著名会计师事务所，他们算的账，连华尔街都认，好莱坞当然也能认。

那普华永道这次犯了这么低级的错误，是因为他们徒有虚名，活干得草率吗？其实也不是。他们干这个活，既有悠久的传统，也有严密的系统。而且这个系统是严格排除机器介入的。

奥斯卡选票是手填的，计票是人工的，结果是不准输入计算机的。为啥？因为怕黑客侵入计算机，干扰结果，或者是提前泄露结果。所以，每届奥斯卡的最终结果，直到颁奖仪式开始，都只有两个人知道，谁啊？就是普华永道的那两名审计师。

对这两个人的要求也很严，他们得牢记结果，不仅写在纸上，还得记在大脑里，同时为了避免堵车、信封丢失等意外情况，他们特意准备了两套一模一样装有奖项结果的信封，两人各带一套，兵分两路前往仪式现场，路线都不能一致。在现场，他们俩会分别站在舞台的左右两侧，这样能保证颁奖嘉宾无论从哪边都可以拿到需要的信封。

你看，考虑得很周全吧。但是没有用，人就是人，是一个脆弱的，非常容易受情绪干扰的物种和系统。

你想，全世界都在等颁奖结果，全世界只有这两个人提前知道颁奖结果，我要是这两个审计师中的一个人，我也很兴奋，那是站在世界之巅的感觉，脑子一抽抽，什么错误都可能犯。

我们再来看一下这个乌龙事件：这件事很重要；干这件事的公司既有经验，也重声誉，干事的系统也尽可能地考虑到了所有细节和意外。但是，就这样也没用。只靠人，就连这么重要、简单的活儿也不容易干得好。这一点是不是很绝望？

好了，问题来了。在建立安全系统这件事上，人不可靠，联系到昨天的案例，机器也不可靠，那怎么办呢？怎么才能建立一个安全的系统呢？

其实，答案也许既不在机器一边，也不在人这一边，而是怎么处理好机器和人的关系。

回想一下昨天的那个案例，要命的问题，不是机器本身不可靠，而是人被当成了机器的零件。机器一旦发出警报，指望人像一个电子元件那样，马上做出准确的、灵敏的反应，是不可能的。

比如说，你家里有一个烟雾警报器，这本身是安全的保证。但是，它要是过度灵敏，抽根烟它报警，炒个菜它也报警，扫个地它也报警，那最终结果，一定是你干脆把它关了。所以，那个“狼来了”的故事，其实是一个很深刻的隐喻。一次没有狼，两次没有狼，大伙儿就再也不信了。人始终会保持对信息的判断权，人永远不会是机器的一个零件。

所以你要建立一个安全系统，那系统必须倒过来。机器服务于人，关系才能理顺。

最近我看到一个航空业的例子，就很说明问题。

波音公司生产的飞机上，原来是动不动就发警报，因为飞机，安全是重中之重，但是老是发警报，要么把飞行员搞得手足无措，要么让飞行员对警报熟视无睹。

后来在生产777型客机的时候，波音公司就对警报系统做了优化。简单说，就是做了个警报的分层，把不同的紧急状况分成四个层级。

比如说，最低一级的警报。这个级别只是在屏幕上有文字提示。比如说，现在快降落了，但是起落架还没有放哦。这个只是提醒，而且有充分的后备方案，所以不用吱哇乱叫。

第二个级别情况就稍微严重一点，比如机舱内空调出了故障，飞行员得看一下故障到什么程度再做判断。这时候，除了屏幕的警示文字，还会亮起警示灯。但是灯是不叫的。

第三个级别就比较严重了，比如发动机失火。这种情况虽然严重，但飞行员还是有足够的应对方案的。这时候警示灯、警示文字，都会出现，而且灯会变成更显眼的红色，除了视觉提醒，还会响起警报声。

那什么情况才能触发最高级别的警报呢？在现代的波音飞机中，只有飞行过程中出现了动力失速这一种情况，才能触发最高级别的警报。因为一旦失速，要是不立刻采取措施，飞机很可能面临坠毁的危险。这时上面说的红色警示灯、警示文字、语音警报都会同时出现，警示文字会变成最显眼的红色。这还不够，飞机的操纵杆也会剧烈振动，要让飞行员能够立刻看到、听到、感觉到飞机正在失速，必须立刻采取措施。

你看，这个改造，看起来只是一个优化，只是把警报分级了嘛，但这其实是一个实质性的改变：安全系统中人和机器关系颠倒过来了。

原来，机器只要有一丁点儿问题，就要指挥人。而现在是，机器只是人的助手。机器给出的任何信号，都必须考虑到人的反应，照顾到人的接受程度。安全的最终责任，其实交给了人。也许这才是未来所有安全系统该有的样子。

今天的最后，发一点我自己的感慨。

人类社会一直这样，每次机器发生一点进步，人类社会都会出现一种声音，机器要替代人了。其实这件事从来没有发生。

机器每前进一步，人都会水涨船高地前进一步。没有汽车之前，就没有汽车司机。有了飞机，才有了人类的飞行员，有了计算机，就有了编程人员。

人类这个物种，总是能在机器的基础上重新定位自己的存在，并且握有对文明世界的主导权。

麦克卢汉说得好，整个文明史，其实都只是人的延伸。

今天就聊到这里。罗辑思维，明天见。

