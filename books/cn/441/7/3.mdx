---
---
---
title: 大脑对抗基因论
---




陈颖青

资深出版人

从自我意识的角度看，作者主张的“大脑对抗基因论”会赢得我个人的认同，毕竟长生不老是许多人追求的梦想，如果对抗成功，意识脱离基因宰制，成为虚拟世界的“个体”，那么随心所欲，纵浪大化，“意识我”的世界从此将海阔天空，自由发展。不过认同归认同，理性来看这个问题却可能不是那么简单就能认同或不认同。

从工程的角度看，基因是一种制造生命的“蓝图”，蓝图如果制造出一个多工或多意义的物品，你就很难限制那个最后成品，只能用于原始设计的特定用途上。例如你根据蓝图造了一把菜刀，它完全符合砍肉、切菜、拍蒜的用途，但它能不能用来当美工刀呢？虽然难用，但好像也没什么不可以。能不能用来挖土种菜？搅拌洗米？打乒乓球？似乎也都可行。

这世界上本来为了某用途而诞生的某物，最后却转成他用的例子太多了。人类大脑完全有可能自己找到未来发展的用途，而脱离作为基因载体与复制子的宿命。逻辑上以及进化史上这都是可能的，而且可能性还不低。

但我马上想起的类比，是这几年各界先进对人工智能发展的忧虑，包括像史蒂芬·霍金等人所担忧的，一旦人工智能发展到取得自我意识，到时候恐怕就是人类末日到来的时刻了。因为人工智能的能力一定远胜人脑，而且我们不确定“他们”还会不会对人类保有适当的尊敬或友爱情谊。

感觉基因如果有意识的话，心情应该就像现在人类忧虑人工智能的发展一样吧。

在科幻领域，小说家很早就担心过相同问题：一旦机器智能到达某个临界点，智慧机器开始设计新一代的智慧机器，那将会是以几何级数快速增长的先进智慧机器时代的诞生。为了避免先进智慧机器消灭人类，著名的科幻作家艾西莫夫构筑了著名的“机器人三法则”：

一、机器人不得伤害人类，或坐视人类受到伤害而不作为；

二、机器人必须服从人类的命令，除非违背第一法则；

三、机器人必须保护自己的安全，除非违背第一与第二法则。

埃西莫夫的机器人系列所有情节，都在这三法则上大玩逻辑游戏，让人叹为观止。虽然人工智能学界对机器人三法则有不同评价，但大家却都有一个共识，那就是在发展超级人工智能的时候，应该先发展一个可以约制机器人消灭人类的某种“道德命令”，安装在机器人的系统底层。

从这个角度思考，有没有可能基因在发展意识的时候，已经在意识底层先铺上了一层防止背叛的“保险”呢？

在认知神经科学研究的许多经典案例里，有一个特别让我印象深刻的案例，是一位丧失情绪欲望的建筑工人。他在一场工地事故中被钢筋贯穿头颅，经过抢救以后，奇迹似的存活了下来，只不过他丧失了情感好恶的欲望。没有了好恶，他就失去了欲望，无法决定何者是他想要或不想要的，因此他失去做决定的能力，因而也失去行动的能力。

他的日常逻辑分析能力都没问题，但就是无法决定什么是他“想”要的，什么不是。失去欲望能力的大脑，即使有完整的“能力”，也会变得无法行动。

人类的大脑是设计来回应物质世界外部条件的机器，哪里有水、有食物，哪里温暖，哪里没有毒蛇猛兽，物质条件经过感官读取之后，转换为神经脉冲，在大脑中计算，决定采取的行动。

大脑虽然是信息处理器，但这个处理器底层，是对物质世界的侦测。苦味分子决定我们对“痛苦”的精神感受；甜味分子让我们心情大好；酸味分子带给我们心酸滋味；光线明度让我们降低对幽暗的恐惧。

如果意识脱离了物质世界，在这个处理器底层，过去我们仰赖物质刺激而建立的情绪好恶动机，还会存在吗？我们变成不再追求碳水化合物，而改为追求电力能源——取得更多电力储备的时候，我们是觉得甜（如吃糖），还是觉得鲜（如吃肉）呢？

物质决定了我们欲望的性质，并且也是我们动机的基础，一旦我们脱离了物质，我们的欲望和动机还会和以前一样吗？如果我们只要输入爱情动作片情节就会让中央处理器兴起一阵高潮，那么求偶、恋爱这种物质世界的动机还会存在吗？还会有恋人、伴侣、配偶、家庭这种物质现象吗？

如果家庭不再必要，人类社会的架构会不会崩解呢？物质决定了人类从基本好恶的情绪模块到最高层次的社会结构和行为规范。“碳基”处理器真的能变身为“硅基”处理器吗？这中间的断层恐怕不是一个细胞一个细胞地置换就能够解决的问题。