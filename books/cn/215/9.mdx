---
---
---
title: 九 如何确定网页和查询的相关性
---




[我们已经谈过了如何自动下载网页、如何建立索引、如何衡量网页的质量(PageRank)。我们今天谈谈如何确定一个网页和某个查询的相关性。了解了这四个方面，一个有一定编程基础的读者应该可以写一个简单的搜索引擎了，比如为您所在的学校或院系建立一个小的搜索引擎。]





我们还是看上回的例子，查找关于“原子能的应用”的网页。我们第一步是在索引中找到包含这三个词的网页（详见关于布尔运算的系列）。现在任何一个搜索引擎都包含几十万甚至是上百万个多少有点关系的网页。那么哪个应该排在前面呢？显然我们应该根据网页和查询“原子能的应用”的相关性对这些网页进行排序。因此，这里的关键问题是如何度量网页和查询的相关性。





我们知道，短语“原子能的应用”可以分成三个关键词：原子能、的、应用。根据我们的直觉，我们知道，包含这三个词多的网页应该比包含它们少的网页相关。当然，这个办法有一个明显的漏洞，就是长的网页比短的网页占便宜，因为长的网页总的来讲包含的关键词要多些。因此我们需要根据网页的长度，对关键词的次数进行归一化，也就是用关键词的次数除以网页的总字数。我们把这个商称为“关键词的频率”，或者“单文本词汇频率”（TermFrequency)，比如，在某个一共有一千词的网页中“原子能”、“的”和“应用”分别出现了2次、35次和5次，那么它们的词频就分别是0.002、0.035和0.005。我们将这三个数相加，其和0.042就是相应网页和查询“原子能的应用”相关性的一个简单的度量。概括地讲，如果一个查询包含关键词w1,w2,...,wN,它们在一篇特定网页中的词频分别是:TF1,TF2,...,TFN。（TF:termfrequency)。那么，这个查询和该网页的相关性就是:TF1+TF2+...+TFN。





读者可能已经发现了又一个漏洞。在上面的例子中，词“的”站了总词频的80%以上，而它对确定网页的主题几乎没有用。我们称这种词叫“应删除词”（Stopwords)，也就是说在度量相关性是不应考虑它们的频率。在汉语中，应删除词还有“是”、“和”、“中”、“地”、“得”等等几十个。忽略这些应删除词后，上述网页的相似度就变成了0.007，其中“原子能”贡献了0.002，“应用”贡献了0.005。





细心的读者可能还会发现另一个小的漏洞。在汉语中，“应用”是个很通用的词，而“原子能”是个很专业的词，后者在相关性排名中比前者重要。因此我们需要给汉语中的每一个词给一个权重，这个权重的设定必须满足下面两个条件：





1.一个词预测主题能力越强，权重就越大，反之，权重就越小。我们在网页中看到“原子能”这个词，或多或少地能了解网页的主题。我们看到“应用”一次，对主题基本上还是一无所知。因此，“原子能“的权重就应该比应用大。





2.应删除词的权重应该是零。





我们很容易发现，如果一个关键词只在很少的网页中出现，我们通过它就容易锁定搜索目标，它的权重也就应该大。反之如果一个词在大量网页中出现，我们看到它仍然不很清楚要找什么内容，因此它应该小。概括地讲，假定一个关键词w在DW个网页中出现过，那么DW越大，w的权重越小，反之亦然。在信息检索中，使用最多的权重是“逆文本频率指数”（Inversedocumentfrequency缩写为ＩＤＦ），它的公式为ｌｏｇ（Ｄ／Ｄｗ）其中Ｄ是全部网页数。比如，我们假定中文网页数是Ｄ＝１０亿，应删除词“的”在所有的网页中都出现，即Ｄｗ＝１０亿，那么它的ＩＤＦ＝log(10亿/10亿）=log(1)=０。假如专用词“原子能”在两百万个网页中出现，即Ｄｗ＝２００万，则它的权重ＩＤＦ＝log(500)=6.2。又假定通用词“应用”，出现在五亿个网页中，它的权重ＩＤＦ=log(2)则只有0.7。也就只说，在网页中找到一个“原子能”的比配相当于找到九个“应用”的匹配。利用IDF，上述相关性计算个公式就由词频的简单求和变成了加权求和，即TF1*IDF1+TF2*IDF2＋...+TFN*IDFN。在上面的例子中，该网页和“原子能的应用”的相关性为0.0161，其中“原子能”贡献0.0126，而“应用”只贡献了0.0035。这个比例和我们的直觉比较一致了。





ＴＦ／ＩＤＦ（termfrequency/inversedocumentfrequency)的概念被公认为信息检索中最重要的发明。在搜索、文献分类和其他相关领域有广泛的应用。讲起TF/IDF的历史蛮有意思。IDF的概念最早是剑桥大学的斯巴克－琼斯[注：她有两个姓］(KarenSparckJones)提出来的。斯巴克－琼斯１９７２年在一篇题为关键词特殊性的统计解释和她在文献检索中的应用的论文中提出ＩＤＦ。遗憾的是，她既没有从理论上解释为什么权重ＩＤＦ应该是对数函数ｌｏｇ（Ｄ／Ｄｗ）（而不是其它的函数，比如平方根），也没有在这个题目上作进一步深入研究，以至于在以后的很多文献中人们提到ＴＦ／ＩＤＦ时没有引用她的论文，绝大多数人甚至不知道斯巴克－琼斯的贡献。同年罗宾逊写了个两页纸的解释，解释得很不好。倒是后来康乃尔大学的萨尔顿（Salton)多次写文章、写书讨论TF/IDF在信息检索中的用途，加上萨尔顿本人的大名（信息检索的世界大奖就是以萨尔顿的名字命名的）。很多人都引用萨尔顿的书，甚至以为这个信息检索中最重要的概念是他提出的。当然，世界并没有忘记斯巴克－琼斯的贡献，2004年，在纪念文献学学报创刊60周年之际，该学报重印了斯巴克-琼斯的大作。罗宾逊在同期期刊上写了篇文章，用香农的信息论解释IDF，这回的解释是对的，但文章写的并不好、非常冗长（足足十八页），把一个简单问题搞复杂了。其实，信息论的学者们已经发现并指出，其实IDF的概念就是一个特定条件下、关键词的概率分布的交叉熵（Kullback-LeiblerDivergence)（详见上一系列）。这样，信息检索相关性的度量，又回到了信息论。





现在的搜索引擎对TF/IDF进行了不少细微的优化，使得相关性的度量更加准确了。当然，对有兴趣写一个搜索引擎的爱好者来讲，使用TF/IDF就足够了。如果我们结合上网页排名(PageRank)，那么给定一个查询，有关网页综合排名大致由相关性和网页排名乘积决定。