---
---
---
title: 3 Big Brother Is Listening
---






In November 2021, Chinese tennis star Peng Shuai took to Weibo to make a startling accusation of sexual assault against the former vice premier Zhang Gaoli. Within twenty minutes, she was silenced by Chinese censors.1 Soon after, all mentions of her name were purged from Chinese social media.2 Civil rights activists, tennis luminaries like Naomi Osaka and Serena Williams, and New York Times investigative journalists were vocal in their support for her; within weeks, the Women’s Tennis Association (WTA) had suspended all its tournaments in China. “If powerful people can suppress the voices of women and sweep allegations of sexual assault under the rug,” declared WTA president and CEO Steve Simon, “then the basis on which the WTA was founded—equality for women—would suffer an immense attack.”3

China reacted to the mounting pressure by circulating a screenshot of an email allegedly authored by Shuai in which she disclaimed the allegation.4 They also promoted photographs from a video call between Shuai and the International Olympic Committee, which were widely derided as “stage-managed appearances” orchestrated by the government to make it seem like Shuai was well.5 Protestors at the 2022 Wimbledon games wore shirts asking WHERE IS PENG SHUAI? to reflect lingering concerns that Shuai continues to be censored.6

Although the Chinese constitution ostensibly secures the right to freedom of expression, the Chinese government regularly censors or prohibits speech it believes is offensive or undermining to the Communist Party.7 China is hardly unique in this respect—other examples abound, from North Korea to Iran and Russia. Within hours of its invasion of Ukraine, Vladimir Putin yanked independent news agencies off the air, blocked radio shows, including the Voice of America and Radio Free Europe, cut off access to websites and social media, and restricted tens of millions of Russians’ use of Twitter.8 In On Liberty, John Stuart Mill called attention to the insidious dangers posed by such governmental actions, arguing that humans can only “make some approach to knowing the whole of a subject … by hearing what can be said about it by persons of every variety of opinion, and studying all modes in which it can be looked at by every character of mind. No wise man ever acquired his wisdom in any mode but this; nor is it the nature of human intellect to become wise in any other manner.”9 Using censorship, law, and brute force, governments like those of China and Russia chill free speech to prevent their people from learning the truth about them.10

Repressive moves like those are terrifying enough. Even scarier is the fact that neurotechnology allows governments to move beyond the surveillance of what people are writing, saying, or doing to their very thoughts. It has already begun.11

In the People’s Republic of China, Deayea, a Shanghai-based technology company, has revealed that conductors of the busiest high-speed rail line in the world—the Beijing–Shanghai line—have EEG devices embedded in the brims of their hats.12 So do workers at utilities like Hangzhou Zhongheng Electric and the State Grid Zhejiang Electric Power.

It isn’t just state employees who are having their brains monitored, nor is monitoring limited to fatigue or emotional distraction. In 2019, the Wall Street Journal reported that a primary school in Jinhua required its fifth-grade students to wear EEG headsets, which fed data to their teachers, parents, and the state. The US-based manufacturer and supplier of the devices, BrainCo, had shipped more than twenty thousand of them to China already.13 About an inch wide and made of black plastic, the Focus 1 (or Fu Si) headsets are worn across students’ foreheads. A light in the middle blazes red, yellow, or blue to signal the student’s engagement.14 More intensive brain wave data is sent in real time to the teacher’s computer, whose software generates real-time alerts about students’ attention levels.

The teachers overseeing the program believed that brain monitoring substantially improved their students’ engagement. One student agreed, saying he had “become more attentive in class. All of my assignments come back with perfect grades.”15 Other students are less sanguine, having been punished by their parents for their low attention scores.

The story quickly went viral on social media, with photos and pictures of the students wearing the EEG devices circulating on Weibo. Chinese officials quickly quashed all discussion of the program within its borders, using its censorship machinery to scrub any mention of it from social media.16

Other governments are investing in brain biometrics, using brain activity to authenticate individuals, purportedly to improve border security and personal authentication. The collection of brain biometrics poses a much more profound threat to liberty than even the use of facial recognition technology, as it puts neurotechnology on a collision course with freedom of thought, a right that is already very much under siege.

Obviously not all government investment in brain research and neurotechnology is bad. They can and do fund and enable major research with an aim to alleviate human suffering.





Governments’ Big Bets on the Brains


Disorders of the brain are the leading cause of disability and the second leading cause of death worldwide, and they have risen dramatically over the past thirty years.17 So, in April 2013, when President Barack Obama unveiled the BRAIN Initiative (Brain Research Through Advancing Innovative Neurotechnologies) to give scientists “the tools they need to get a dynamic picture of the brain in action and better understand how we think and how we learn and how we remember,”18 it received widespread and universally positive media attention. The initial $100 million Obama earmarked has grown over the past decade to nearly $5 billion under presidents Trump and Biden.19 Among the work it has funded is research by Professor Edward Chang and his team at the University of California, San Francisco, that has yielded breakthroughs in “speech neuroprosthesis,” tools that translate brain signals into text, allowing paralyzed people with anarthria to communicate.20

In 2016, leading scientific academies around the world called on governments to work together to carry out and fund basic research targeted at diagnosing, preventing, and treating disorders of the brain.21 Governments heeded the call, and created an International Brain Initiative with representatives from some of the world’s major brain research projects, to encourage global research collaborations and shared data standards and findings. 22

Along with the scientific research, there’s been a greater focus on the ethical implications of brain research. Shortly after the launch of the US BRAIN Initiative, President Obama asked his Presidential Commission for the Study of Bioethical Issues (of which I was a member) to consider “the potential implications of the discoveries that we expect will flow from studies of the brain … questions, for example, relating to privacy, personal agency, and moral responsibility for one’s actions; questions about stigmatization and discrimination based on neurological measures of intelligence or other traits; and questions about the appropriate use of neuroscience in the criminal-justice system, among others.”23 In our two-volume report, Gray Matters,24 we recommended that governments prioritize funding for research on brain health while supporting efforts to increase the public understanding of neuroscience and its applications. In addition, we called for equitable access to neurotechnology, offered targeted guidance on brain research for people with impaired consent, and pressed for a deeper understanding of the use of neuroscience in the legal system.

Since then, the International Brain Initiative has called upon neuroscientists to take a moral stance to guide the responsible progress of neuroscience research.25 A moral stance that ought to include advocacy for the protection of freedom of thought.





The Forgotten Right to Freedom of Thought


In their majority opinion in the 1942 case Jones v. City of Opelika, Supreme Court justices Murphy, Black, Douglas, and Chief Justice Stone articulated the widely shared belief that freedom of thought is absolute, but even “the most tyrannical government is powerless to control the inward workings of the mind.” Now with advances in neurotechnology we can no longer make that claim, and so we’re left to confront a serious threat to our freedom with outdated legal precedents to guide us.

Freedom of thought is explicitly protected as an absolute human right in Article 18 of the Universal Declaration of Human Rights, Article 18(1) of the International Covenant on Civil and Political Rights (ICCPR) (the multilateral treaty that commits states to respect the civil and political rights of individuals),26 and Article 9 of the European Convention on Human Rights.27 That means, unlike mental privacy that balances the privacy rights of the individual against societal interests on a case-by-case basis, the freedom of thought of an individual should never be violated in the name of the common good.28 Until recently, the right to freedom of thought has almost entirely applied to the protection of religious freedoms and has been under-theorized in other contexts.

In the United States, the First Amendment of the Constitution has long been understood to protect freedom of thought as a precursor to freedom of speech, which implicitly includes the right to read what one wants, think what one thinks, and not be forced to speak words or sentiments that are antithetical to our beliefs.29 This is why state governments cannot, for example, require schoolchildren to recite the Pledge of Allegiance or be forced to recite rote facts they do not wish to say.30 But because state regulation of thought has arisen so rarely, there is little to no guidance on what constitutes thought or what state actions would violate that freedom.

Now that artificial intelligence technology can increasingly infer our thoughts from our digital activities and neurotechnology can decode our emotions and one day soon perhaps even our thoughts, scholars and human rights advocates are calling for updates to international conventions.

These concerns are what prompted the UN special rapporteur for freedom of thought and religion, Dr. Ahmed Shaheed, and his team to reach out to me in 2021, to discuss a report he was preparing for the United Nations General Assembly on freedom of thought. Dr. Shaheed talked with me about how narrowly the right has been applied until now.31 And how the use of neurotechnology by individuals, corporations, and governments could pose new threats to freedom of thought.

When I discuss “thought” as a legal interest or concern, I include in it all the ideas, reactions, reflections, images, memories, and ruminations we turn over in our minds.32 But there is very little scientific or philosophical consensus around what “thought” should or does include. Other scholars, for example, consider the subconscious processes of the mind and one’s automatic reflexes to be “thought.” Jan Christoph Bublitz, a legal scholar at the University of Hamburg who has focused extensively on the issue, says that while the “forum internum is protected unconditionally, it is less clear what this inviolable sphere comprises.”33 Does it include all mental states? Does it include emotions and dreams? Or just “thought” in the stricter sense? Bublitz recognizes the urgency of deciding this issue, since neurotechnology can soon be used to “surmount the natural boundaries of the mind.”34

I worry that if we include too much within the legal definition of “thought,” we may interfere with ordinary human interactions. Human beings try to read one another’s minds all the time. One of the earliest skills we develop during childhood is what is known as theory of mind—trying to predict what another person is thinking. If we go too far and define freedom of thought as the prohibition of every attempt to read each other’s minds, we risk criminalizing human understanding.

This is why it’s useful to conceptualize cognitive liberty as a bundle of rights that includes freedom of thought, the right to self-determination, and the right to mental privacy over our thoughts and mental processes. As an absolute human right, freedom of thought protects against governmental intrusions into our conscious thought and memories, while other aspects of brains and mental processes should be protected by mental privacy and an individual right to self-determination. This allows for the space that we need for innovation, the deployment of human empathy, and allowing some violations of mental privacy based on necessity and proportionality when societal interests call for doing so (e.g., monitoring a train engineer’s brain for signs of fatigue).

When Dr. Shaheed presented his report to the UN General Assembly in October 2021, he asked the assembly to “further clarify the freedom’s scope and content” while offering a framework in which to do so.35 That framework includes the right not to reveal one’s thoughts, not to be penalized for one’s thoughts, and not to have one’s thoughts manipulated.36





“Passthoughts” as a Gateway to Brain Surveillance


Assume that Meta, Google, Microsoft, and other big tech companies soon have their way, and neural interface devices replace keyboards and mice. In that likely future, a large segment of the population will routinely wear neural devices like NextSense’s biosensing EEG earbuds, which are designed to be worn twenty-four hours a day. With widescale adoption of wearable neurotechnology, adding our brain activity to nationwide identification systems is a near-term reality.37

One of the most extraordinary discoveries of modern neuroscience is the uniqueness of each person’s functional brain connectome (its physical wiring), especially in the brain areas devoted to thinking or remembering something.38 Because of this, algorithms can be used to analyze our brain activity and extract features that are both unique to each person and stable over time.39 How your brain responds to a song or an image, for example, is highly dependent upon your prior experiences. The unique brain patterns you generate could be used to authenticate your identity.40

Nationwide identification systems vary by country but generally involve the assignment of unique identification numbers, which can be used for border checks, employment screenings, health-care delivery, or to interact with security systems.41 These ID numbers are stored in centralized government databases along with other significant personal data, including birth date and place, height, weight, eye color, address, and other information.42 Most identification systems have long included at least one piece of biometric data, the static photo used in passports and driver’s licenses. But governments are quickly moving toward more expansive biometric features that include the brain.43

Biometric characteristics are special because they are highly distinctive and have little to no overlap between individuals. As the artificial intelligence algorithms powering biometric systems have become more powerful, they can identify unique features in the eyes and the face, or even in a person’s behavior.44 Brain-based biometric authentication has security advantages over other biometric data because it is concealed, dynamic, nonstationary, and incredibly complex.45

The promise of greater security has led countries to invest heavily in biometric authentication. China has an extensive nationwide biometric database that includes DNA samples, and it also makes widespread use of facial recognition technology.46 Chinese authorities in the Xinjiang Uyghur Autonomous Region have conducted mass collections of biometric data from the Uyghur people and used it for targeted discrimination.47

The United States has also massively expanded its collection of biometric data. A recent report by the US Government Accountability Office detailed at least eighteen different federal agencies that have some kind of facial recognition program in place.48 US Customs and Border Protection includes facial recognition as part of its preboarding screening process,49 and an executive order signed by President Trump in 2017 required the United States’ top twenty airports to implement biometric screening on incoming international passengers.50

Increasingly, governments are investing in developing brain biometric measurements. The US Department of Defense recently funded SPARK Neuro, a New York–based company that has been working on a biometric system that combines EEG brain wave data, changes in sweat gland activity, facial recognition, eye-tracking, and even functional near-infrared spectrometry brain imaging (fNIRS), a particularly promising (if expensive) technology for brain authentication, since it is wearable, can be used to monitor individuals over time, can be used indoors or outdoors while a person is moving or at rest, and can be used on infants and children.51 China has been funneling substantial investments into EEG and fNIRS as well.

For biometric features to be successfully used for authentication, they must have universality, permanence, uniqueness, and be secure against fraud. Over time, static biometrics like facial IDs and fingerprints have become prone to spoofing. Functional biometrics, such as brain activity, are less prone to attack. That feature has motivated researchers like Jinani Sooriyaarachchi and her colleagues in Australia to develop scalable brain-based authentication systems. In one of their most recent studies, they recruited twenty volunteers and asked them to listen to both a popular English song and their own favorite song while their brain wave activity was recorded with a four-channel (an electrode capturing brain wave activity is called a channel) Muse headset. Afterward, the researchers analyzed their recorded brain wave activity using an artificial-intelligence classifier algorithm. Remarkably, they achieved 98.39 percent accuracy in identifying the correct participant when they listened to the familiar song, and a 99.46 percent accuracy when they listened to their favorite song.52

Using an eight-channel EEG headset on thirty research subjects, another group achieved a similar 98 percent accuracy in authenticating participants by their brain wave data after they’d looked at novel images. It might not even take eight or even four electrodes to achieve the same result. Even with just a single-channel EEG headset, researchers have achieved 99 percent accuracy in distinguishing between participants when they performed the same mental tasks.53

Most of these studies had a small number of participants; it is not yet clear if neural signatures will be as accurate at scale, when billions rather than dozens of people must be authenticated. EEG is inherently noisy—meaning the signals the electrodes pick up can come from eye-blinking or other movement, which can make it hard to tell the difference between brain activity or interference. But researchers have made substantial progress in developing pattern classifiers that filter noise, allowing them to discriminate between individuals based on their resting-state EEG brain wave activity and when performing tasks.54 As noted previously, EEG devices have been used to recover sensitive information from a person’s brain, such as their PIN codes,55 and their political and religious ideologies.56 Obviously, this poses clear risks to our digital and physical security.

Governments can already tap our phone conversations and snoop on us digitally. Will they similarly tap our brain activity data without our knowledge or consent? Will they deploy AI programs to search our brains for terrorist plots? Will they gather neural data to make inferences about individuals’ political beliefs to predict and prevent peaceful protests? China is reportedly already doing so.

These and other questions underscore the need to update our right to freedom of thought. We must take steps now to ensure that brain-based authentication will not become a back door to spying on our thinking. Which is no small challenge if brain biometrics increasingly depend upon decoding our functional brain activity, as this requires decoding our thoughts. It’s possible that the only way forward is to limit the data that governments can obtain from our brain to interpretations of our brain activity, and not the raw brain data itself. An algorithmic interpretation of that data that simply confirms “this is a match” or “this is not a match” would limit the further processing of brain activity data by government actors. To cede more may well put our cognitive liberty at perilous risk.

But even limited interpretations of brain activity may not suffice to preserve our sphere of thinking freely. Whatever security advantages we gain from brain-based biometrics may be outweighed by the impact of giving governments the power to track our brains.





The Chilling Effects of Brain Surveillance


The chilling effects of government surveillance have been extensively documented. Dr. Elizabeth Stoycheff, a professor of communications at Wayne State University, studies the ways that mass surveillance affects people’s behavior.57 In one study, Stoycheff created a baseline psychological profile of research participants based on their surveyed ideological beliefs, personality traits, and online activity. Then she subtly reminded a random subset of those participants that they were subjects of mass government surveillance. Afterward, all the participants were shown a made-up newspaper headline which stated that the United States had undertaken airstrikes against the Islamic State in Iraq and were asked their opinion about it, including how they thought other Americans would feel and whether they would be willing to voice their own opinions in public. The participants who had been primed to think about mass government surveillance were significantly more reluctant to share their nonconforming views, even when their personality profiles predicted otherwise. This underscores the significant impact of self-censorship in response to surveillance and reinforces decades of research on the “spiral of silence” that was first identified in 1974 by the German political scientist Elisabeth Noelle-Neumann—the phenomenon in which the perception that one’s opinion is unpopular makes one reluctant to express it.58

What most dismayed Stoycheff was people’s cavalier dismissal of surveillance. “So many people I’ve talked with say they don’t care about online surveillance because they don’t break any laws and don’t have anything to hide. I find these rationales deeply troubling,” she mused. “It concerns me that surveillance seems to be enabling a culture of self-censorship because it further disenfranchises minority groups. It is difficult to protect and extend the rights of these vulnerable populations when their voices aren’t part of the discussion. Democracy thrives on a diversity of ideas and self-censorship starves it. Shifting this discussion so Americans understand that civil liberties are as fundamental to the country’s long-term well-being as thwarting very rare terrorist attacks is a necessary move.”59

Freedom of thought is at the heart of those civil liberties; without it, the diversity of ideas necessary for human flourishing is silenced. Just as surveillance chills people from sharing their nonconforming views, thought surveillance will inevitably lead people to attempt thought modification—trying to silence their inner voices, risking a dangerous spiral that ends with the suppression of even their innermost views. Making it of paramount importance that we prohibit governments’ surveillance of thought.60

Government surveillance of brain activity will inevitably push us toward greater conformity. With greater conformity comes a passive acceptance of authority and authoritarianism, either out of fear or in hopes of appearing cooperative, even when that conflicts with one’s own moral compass.61 Children are particularly susceptible to pressure to conform and so are even likelier to try to redirect divergent thinking for fear of being ostracized. Many of the worst atrocities are “crimes of obedience”: acts carried out in response to orders from authority that violate legal and social norms.62

To know the difference between right and wrong, and to decide for ourselves what that is, we must have the freedom to think critically about the world around us.63 Freedom of thought guarantees us a private space to think and self-reflect, where we are free from fear of reprisal. This gives us the wherewithal to reject orders that we know are wrong.

This freedom is critical for all of us, not just great thinkers. John Stuart Mill made this point eloquently in On Liberty, arguing that “it is as much, and even more indispensable to enable average human beings to attain the mental stature which they are capable of.”64 When we have the freedom to think, we can decide for ourselves whether we want to be angry about a setback or an insult from another; we can investigate our feelings and align our instincts with our self-identity.65 But we can do so only in a mental space that is free from government surveillance.





A Thought Experiment on Thought Crime


On the first day of my criminal law class for first-year law students, I assign the classic science fiction film, Minority Report, which is based loosely on a Philip K. Dick short story. Set in Washington, DC, and Northern Virginia in 2054, the film follows the pursuits of the Precrime unit, an elite group of police who, relying on intelligence from “Precog” psychics, arrest potential criminals before they commit their crimes. The upside is that the Precrime unit has eliminated all planned murders in its jurisdiction. The downside is that they are suppressing a minority view among the Precogs, that a suspect could still choose a different future.

After discussing the film, I ask my students to consider an alternative future in which we could use neurotechnology to anticipate future crimes. If new technology revealed that someone was contemplating murder, should we arrest them? Even when I head off the question of the reliability of the technology at the pass by stipulating that it is bulletproof, my students invariably come down strongly against arresting suspects based on their thoughts alone. They worry about the loss of our collective sense of personal security and liberty. They may believe that law enforcement has a role to play in deterring crime, some even citing examples of teenagers intercepted by the police on their way to commit a crime, potentially saving them from a lifetime behind bars. But they believe equally strongly that we should give people every opportunity to renounce their criminal intent and should limit police powers to interfere with individual liberties only when a person actually does something wrong.

Now that I have their attention, I reveal the startling truth: governments are already using neurotechnology to detect people’s thoughts and memories. And they are prosecuting and convicting them based on what they discover.





Interrogating the Brain for Crime


When investigative journalists David Kocieniewski and Peter Robinson broke the story about the ties between Donald Trump’s incoming national security advisor, Michael Flynn, and a company that sells brain wave technology to governments worldwide, surprisingly few people noticed.66 Serving alongside Flynn on Brainwave Science’s board of directors was Subu Kota, a software engineer who had pleaded guilty to selling highly sensitive defense technology to the KGB during the Cold War.67

Brainwave Science sells a technology called iCognative, which can extract information from people’s brains. Among its customers are the Bangladeshi defense forces as well as several Middle Eastern governments.68 Following some successful experiments at the Dubai Police Academy, Emirati authorities have recently deployed the technology in real murder investigations. At least two cases have successfully been prosecuted.69

In one case, the police were investigating a killing at a warehouse. Suspecting that an employee was involved, they forced the warehouse workers to don EEG headsets and showed them images of the crime. Purportedly, a photo of the murder weapon triggered a characteristic “recognition” pattern in one of the employee’s brains (the P300 wave), while none of the other employees showed a similar response. Confronted with that evidence, the suspect confessed, revealing details that only the guilty party could have known.70

First reported in a series of experiments published in Science magazine in 1965, a P300 wave is an event-related potential (ERP) measurement of brain activity,71 or more simply, an automatic brain response that happens when we encounter some specific sensory, cognitive, or motor event. Research subjects wore EEG headsets while listening to sounds and flashes of light that were presented in pairs, with a three-to-five-second delay between them. In the first experiment, light followed light, and sound followed sound. In the second experiment, light was followed randomly by either light or sound, and vice versa. By comparing the participants’ brain activity between the first and second experiments, the researchers discovered a consistent brain response that occurred about three hundred milliseconds after the target stimulus. But its amplitude differed, depending on whether the participant was certain about the target stimulus that would follow or was uncertain about what came next.

Larry Farwell, an independent researcher, wondered whether those signals of certainty and uncertainty might be useful in police interrogations.72 In 1991, in an article titled “The Truth Will Out,” he reported that he had successfully used the P300 waveform to detect concealed information in the brain. Farwell first trained research subjects on a fake espionage scenario, and then had them act it out. Each participant went to a specific location to meet a person, exchanged a password, then asked that person for a file, who passed it to them.

The next day, the research subjects wore the EEG headsets while a series of questions or “probes”—two-word descriptive phrases about the crime scene—were flashed on a computer screen.73 Whereas a traditional polygraph test asks subjects a series of yes and no questions and then analyzes their physiological responses to infer if they are telling the truth, Farwell examined subjects’ brain responses to phrases like “green hat” (relevant to the person they exchanged the file with), “Tim Howe” (relevant), and “Ship Plans” (relevant) versus “brown shoes” (irrelevant), “Ray Snell” (irrelevant), or “Plane Plans” (irrelevant). The subjects’ P300 brain signals revealed recognition of the relevant details of the crime but not the irrelevant ones. Because people can’t control their unconscious brain responses, Farwell argued, it would be much harder to “beat” his test.74

In November 2001, when the country was obsessed with terrorism, Farwell was profiled in Time magazine as one of America’s one hundred “breakthrough” scientific innovators.75 The “brain-fingerprinting” technique he developed, the article read, would allow interrogators “to determine if a subject is familiar with anything from a phone number to an al-Qaeda code word.” The CIA funded his research and police departments enlisted him to help solve difficult murder cases. But for all the popular enthusiasm, scientists couldn’t replicate Farwell’s findings and eventually rejected his methods as little more than clever marketing.

Despite the decades that have passed since, most scientists remain appropriately skeptical about the scientific validity of brain fingerprinting for criminal interrogation. The design of the key phrases or images to test people with requires substantial expertise and involves a degree of subjectivity, which some scientists have called more art than science. Although Farwell became one of the original founders of Brainwave Science (a partnership that ended with a series of lawsuits over disputed patents), and Robin Palmer, a former criminal defense lawyer from South Africa, has independently validated some of his findings,76 the otherwise broad and seemingly warranted derision of the technique by the scientific community makes it all the more troubling that governments worldwide have used it as often and as recently as they have.

Some of the earliest efforts were at the behest of criminal defendants, who hoped the test would validate their claims of innocence.77 In 1978, Terry Harrington was convicted for the murder of John Schweer, a nighttime security guard in Iowa.78 Harrington appealed his conviction and was eventually granted a new trial in 2001, and the state of Iowa decided not to try him again. At one point during the appeals process, he consulted with Dr. Farwell, who developed a series of unique probes based on previously undisclosed evidence from police files and Harrington’s alibi. In his expert report, Farwell claimed that Harrington did not recognize any of the crime details from the police files, but that his brain did register recognition of the alibi probes.79 Although the Iowa Supreme Court ultimately decided the case on other grounds, by admitting the expert testimony at trial, it paved the way for the future introduction of brain-fingerprinting evidence in criminal cases in Iowa, as the judge found it admissible.

More commonly, it is the police who seek to use the technology. James B. Grinder was the primary suspect in the brutal rape and murder of Julie Helton in 1984, but there wasn’t enough forensic evidence to connect him to her death.80 The police asked Grinder if he would be willing to submit to brain fingerprinting. Certain he could beat the test, Grinder agreed. When the results revealed brain activity consistent with his recognition of the crime scene, Grinder pleaded guilty and was sentenced to life in prison without the possibility of parole.81 While there was still a chance that a judge would find the evidence scientifically inadmissible and exclude it, Grinder didn’t want to risk facing the death penalty.

Despite that success, the practice has yet to become widespread in the United States, not because of concerns about freedom of thought but because criminal defendants refuse to submit to it voluntarily. As Brainwave Science promotes its adoption worldwide, we can expect its use to continue to spread. Police in India have been using brain-fingerprinting technology since at least 2003. Singapore’s police services purchased brain-fingerprinting technology in 2013; the Florida State police signed a contract to use it in 2014. And Australian counterterrorism authorities are looking into the potential use of brain fingerprinting to determine whether individuals returning from war zones who claim to have been carrying out humanitarian work were in fact involved in the conflicts.82

Brain-fingerprinting technology using P300 is just one of several approaches to probing the brain. A scientifically promising approach uses a different ERP brain response called the N400. You could show a suspect a series of faces that includes their suspected coconspirators. Their N400 brain signals would be more negative for “incongruent” faces that didn’t belong than for “congruent” faces that did. Similarly, you could pair words together like “body” and “lake” versus “body” and “basement” to try to find out where a murder victim’s corpse is hidden.83 DARPA’s Neural Evidence Aggregation Tool program is exploring the promise of N400 signals to interrogate the brain for “congruent” and “incongruent” facts.

Other approaches use functional magnetic resonance imaging (fMRI) to analyze truthfulness. The premise behind fMRI lie detection is that a few key areas of the brain are more active when a person is lying than when they are telling the truth.84 Two companies—Cephos Corporation in Tyngsboro, Massachusetts, and No Lie MRI in San Diego, California—marketed this technology for a time. But it is cumbersome and unvalidated, particularly for “real-world” and high-stakes lies compared to low-stakes lying in controlled laboratory settings.

While various protections afforded to criminal defendants could be brought to bear against the use of these techniques in some countries, most fail to give adequate legal protection against their use. Even the Constitution’s Fourth Amendment protection against unreasonable searches and seizures and the Fifth Amendment privilege against self-incrimination are unlikely to keep the government from probing our brains. Until now, these protections have been held inapplicable in certain contexts, such as when information was obtained from a device manufacturer rather than through a search of a person’s body or home. Similarly, if the police obtain incriminating evidence from a person’s brain, courts may interpret that as physical evidence and thus not subject to the privilege against self-incrimination. Laws in other countries are likely to be interpreted similarly.

We can see a trend in how police are using evidence from other wearable devices to predict the direction this will go. Consider the case of Richard Dabate, charged with murdering his wife in 2015. Dabate told Connecticut police that a masked intruder shot her before tying him up. But the Fitbit device she was wearing revealed that she had still been moving for an hour after Dabate said she was killed.85 Objective evidence from a Fitbit device also became critical in the investigation of the 2016 murder of Nicole VanderHeyden. Her boyfriend, Doug Detrie, became a prime suspect in the killing after police found blood on the floor of their garage and in Nicole’s car. But Detrie claimed he was asleep at the time of her killing and had awoken only once to check on their six-month-old baby. Detrie had been wearing a Fitbit device, and its data corroborated his story. Another man was ultimately arrested for the murder.86

Will we come to regard our brain data in the same way we do Fitbit and GPS data? One of the distinguishing features of brain-fingerprinting technology as opposed to traditional forensic evidence is that you have to question a person or show them images or other stimuli to provoke a brain-based response. This means the person is provoked to create incriminating evidence against themselves, which is more likely to violate existing rights like the right against self-incrimination than the passive creation of evidence by existing fitness trackers. But marry a future in which we wear neurotechnology all the time with the ability of the police to obtain its data and decode it, and the passive tracking of our brain activity may also become a reality that can be used as evidence against us in a criminal investigation. Shouldn’t freedom of thought include protection against having the government use our memories and silent utterances against us?





The Right Not to Reveal One’s Thoughts


In 1890, when future Supreme Court justice Louis Brandeis was thirty-four years old, he worried about the “numerous mechanical devices” that would soon allow “what is whispered in the closet” to be “proclaimed from the house-tops.”87 It wasn’t neurotechnology that was keeping him up at night. Brandeis was fretting about portable cameras and celebrity journalism. He and his law partner Samuel Warren were so concerned about the implications of these advances that they penned a groundbreaking essay that argued for a legal right to privacy. Published in the Harvard Law Review, it would become the foundation for many of our modern-day privacy protections.88 While Brandeis and Warren couldn’t have anticipated governments’ use of neural data, they nevertheless argued for the protection of our “thoughts, sentiments and emotions.” Nearly a century later, in Stanley v. Georgia, the US Supreme Court formally embraced their view that the Constitution secures us against “governmental intrusion into one’s privacy and control of one’s thoughts.”89

After he joined the Supreme Court, Brandeis wrote several prescient opinions about modern technology’s potential impingements on our privacy. In his 1928 dissenting opinion in Olmstead v. United States, he predicted that “The progress of science in furnishing the Government with means of espionage is not likely to stop with wiretapping.… Ways may someday be developed by which the Government, without removing papers from secret drawers, can reproduce them in court, and by which it will be enabled to expose to a jury the most intimate occurrences of the home.”90 Twenty years after Olmstead, the United Nations General Assembly adopted the Universal Declaration of Human Rights, including its Article 18 protections of freedom of thought. By 1966, that right was enshrined in the International Covenant on Civil and Political Rights.

But no one, not even Brandeis, anticipated that governments could one day tap directly into our minds, deciphering the emotions, sentiments, and even unuttered speech that they detect. Nor could they have imagined that we, as a society, might one day acquiesce to such intrusions. But seismic shifts in science and technology are often followed by seismic shifts in our understandings of rights.

In his 2021 report to the UN General Assembly, Special Rapporteur Dr. Shaheed underscored the importance of freedom of thought to one’s “forum internum—a person’s inner sanctum (mind) where mental faculties are developed, exercised, and defined.” These faculties are critical to our ability to “perceive truth, to choose freely and to exist.” Or, as John Stuart Mill cautioned in On Liberty, without freedom of thought, we “dare not follow out any bold, vigorous, independent train of thought, lest it should land [us] in something which would admit of being considered irreligious or immoral.”91 No one can ever become a great thinker if they cannot follow their thoughts to wherever they may lead.

Just as we must take steps to ensure neurotechnology isn’t used as a back door to spying on our thinking, we must also take steps to ensure it isn’t used to weaponize our thought against us.

Once our brains can be probed for crime scene details, it isn’t hard to imagine some governments going further and punishing people for their ways of thinking, especially if they are thinking about organizing to overthrow a tyrannic regime. Will George Orwell’s dystopian vision of thought crime become a modern-day reality?

The risks that accompany the benefits of using our brains as tools of law enforcement go to the very heart of being a thinking human being; the urgency of our need to update our definitions of freedom of thought cannot be overemphasized. The ICCPR’s General Comment 22, last updated in 1993, emphasizes the broad scope of freedom of thought but focuses on freedom of religion and belief. We now need to update our understanding of the international human right to freedom of thought to include our right to think without threat of thought surveillance, and without our thoughts being used against us—whether in a criminal proceeding or any other context. In the chapters ahead, we will explore other aspects of freedom of thought that need updating, including the right not to have our thoughts manipulated or our very capacity for thought assaulted.92

To realize the true promise of neurotechnology, we must learn how to harness it for ourselves. We can’t do that unless we have unfettered access to our own data, an issue we turn our attention to next.