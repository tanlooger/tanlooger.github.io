---
---
---
title: 2 Scientific History and the Idea of Modernity
---







IN THE NINETEENTH CENTURY, historians had championed an explicitly scientific history, and in so doing they had embarked upon a new and challenging kind of enterprise. Until then, historians chronicled, narrated, and assessed historical events, but they did not cast their methods and their goals in the mold of heroic science. Indeed, the heroic model of science itself made science seem eternally true, while history remained contingent. Science developed grand, overarching, and invariable laws; history more modestly dealt with what changed in human affairs.

Once science and history got linked together, dramatically new forms of historical knowledge became possible. Explanatory history—the search for the laws of historical development—was born in the nineteenth century: it bequeathed a powerful analytical tool useful to all peoples trying to make sense of where they had been and what they were becoming. Every history book available today—including those about the “end of history”—reflects the enduring power of that nineteenth-century vision of scientific history.

In the mid-nineteenth century, history became a profession. It began to take on its modern form as an organized, disciplined inquiry into the meaning of the past. Certified professional historians with university training in scientific methods of archival research and documented writing began to claim rights to the past. These new historians developed the model of explanatory history that enabled the West to understand itself and the rest of the world within one universal, secular framework compatible with the universality of Newtonian laws. Building upon the Enlightenment belief that society itself was a human artifact and could be known by humans, scientific historians helped lay the foundations for the modern social sciences.

The nineteenth-century modernization of history rested on a new conception of time drawn from Newtonian science. Western historians made time universal and evolutionary and arrayed all the peoples, structures, and institutions in every epoch along its line, labeling each people and era in terms of its level of development. Time became real and sequential, and historians became those who could measure development by progress toward modern, Western time. This scientific history with its companion idea of modernity eventually erected an intellectual absolutism of its own, but it began, as did the heroic model of science itself, as a challenge to the earlier absolutisms of throne and altar and to histories that were meant to show the hand of God at work among saints and rulers. When the process of creating modern history was completed, Biblical time lay in ruins and the dreams of millenarians came to be seen as grand self-delusions.

It is not easy to grasp the significance of the new scientific conception of time because Westerners take it so for granted. They assume that everyone’s time is the same, that it is a universal continuum experienced by all people in the same fashion. The hour may be different in Tokyo or Tehran, but the concept of time is the same, or so common sense seems to insist. That commonsensical notion is, however, relatively recent and derives most directly from the Newtonian conception of time as an absolute, real, and universal entity. Newtonian laws can predict where a planet will be at any given moment in the year because time is imagined as independent and everywhere the same.

New ways of measuring time foreshadowed and then reinforced the scientific notion of universal time. Western Europeans invented mechanical clocks, as an improvement on sundials and water clocks, in the fourteenth century. Christianity, at least as practiced by monks, seemed to require more punctuality than the other religions of the world. The first of the mechanical clocks were giant show clocks designed for public display on churches or city halls, and they had minimal effect on the lives of ordinary people. In the second half of the fifteenth century, miniaturization made mechanical clocks available to wealthy individuals, and time thus passed, as it were, from the rulers and clergymen to the upper classes. Not until the 1860s did reliable cheap Swiss watches become available to the general population.1 Not surprisingly, many of them were made by Protestant workers to whom historians may now credit not only the modern work ethic but also ways of measuring how long you have been at it. In the early nineteenth century, employers began to force industrial workers to regulate their work habits by the factory clock, bringing to ordinary people the experience of time as an ever-present, standardized sequence of units disciplining the cadences of work and daily life.

The experience of time did not depend entirely or perhaps even primarily on timepieces themselves. In the seventeenth and eighteenth centuries, two new forms of imagining the social world appeared—the novel and the newspaper.2 Both made people think of themselves as living lives simultaneous with other lives in a homogenous time measured by clocks and calendars (and not by relationship to salvation or the hereafter). The readers of novels or newspapers follow the lives of people they will never meet but can readily imagine as acting in time and over time like themselves, because they are contemporaries. In any one novel, many of the characters do not meet each other, but they are all depicted as part of one social world, living simultaneous lives that bring them into unexpected connections with each other. Whether reading alone or in groups (as with early newspapers), readers of novels and newspapers knew that they were reading what many other people were also reading at the same time and reading about people acting in their time frame (unlike the prophetic time frame of the Bible). Thus the very act of reading novels and newspapers established a new kind of mental community based on a version of Newtonian time. It also reinforced expectations that human actions in society, like motion in nature, could be explained in terms of scientific cause and effect.

Crucial transformations in the categories of historical time paralleled the homogenization and standardization of the ordinary person’s experience of present time. But historical time was not neutral or empty. The modern idea of historical time was linear as opposed to cyclical, secular as opposed to religious, universal rather than particular to any epoch, nation, or faith. Most important, it had a direction—that is, it was cumulative in some fashion. The new historical sense of time reproduced the universalizing, standardizing time of the scientists, but for human rather than natural history. Being linear, historical time promised to reveal a higher meaning, but being secular, that meaning could be found only in human affairs, not in divine providence. The new characteristics of time did not appear all at once, and many historians continued to espouse one or more elements of previous time schemas. But by the last decades of the nineteenth century, most educated Westerners possessed a universal and universalizing sense of time that was, moreover, ideally suited to the new age of European imperialism. It gave the West a civilizing mission based on modernization—a process that came to mean making everyone else like the West.

Those who promoted the new notion of time passionately believed that they were inaugurating an age that would surpass in achievement—in progress—all that had come before. To be scientific and modern was not dry and academic; it promised a decisive break with the past, a daring leap into the future, and the prospect of continual progress. Progress and modernity thus marched hand in hand. Belief in modernity meant faith that accumulated knowledge, when diffused and applied, could only lead to improvement, to better living standards. Humans were not simply condemned to repeat their past mistakes, enslaved to tradition. They could instead create a better future through an analysis of human experience. The heroic model of science directly inspired this modern perspective inherited from the Enlightenment. In modernity, improvements could now be imagined in this world, not in some distant pie-in-the-sky paradise.

A new relationship to the facts of history followed from the new conception of time. The disciplining of history, its metamorphosis into a scientific discipline, became possible only once a new notion of time had emerged. If time was imagined as universally the same and history construed as a secular story of its unfolding, then it made sense to train historians in universities according to secular, standardized, scientific methods. The development of new techniques of teaching and research guaranteed the mastery of facts. The master historian would teach students how to distinguish fact from legend by the rigorous examination of documents. History would henceforth depend on research in archives and original sources as tests of the facts. University training would teach an attitude of impartiality toward those facts. This mastery of the facts with its emphasis on patient accumulation of information and relentless curiosity about sources provided the second crucial element in scientific history in the West.





Mastering Time and Inventing Modernity



Before there could be moderns, there had to be ancients, men and women who did not think of history as a body of knowledge revealing a pattern or having a meaning. For the Greeks and Romans, history concerned persons, things, or events but did not exhibit overarching meanings or patterns. History showed only the inexorable effects of human passions, weaknesses, and ambitions. Because it was not a separate entity in itself, it did not depend on any particular idea of time. Time could be repetitive or not, cyclical or something else; no one was sure.3

Building upon Hebrew antecedents, Christianity introduced a new linear notion of time into the Greco-Roman world. The Judeo-Christian line of time literally began at one moment and would end at another, and it revealed God’s purposes. In the Christian schema, the turning points of sacred history—the Creation, Jesus’s life and death, and the prospect of the Last Judgment—set the framework for all historical time. If you carefully opened the pages of the New York Public Library’s well-preserved copy of Werner Rolewinck’s Bundle of Chronologies from 1474, for instance, you would see two lines running in parallel through the text. One line measures time since the beginning of the world and the other measures time before and after the birth of Jesus. The year 2907 after the moment of Creation, for example, corresponded to the year 8622 before Christ’s birth. Rolewinck incorporated the histories of ancient peoples and even legends about such imagined peoples as the Amazons into his account of Biblical history. Sacred history gave all of time its meaning.

The Christian time schema occupied scholars right into the seventeenth century. Archbishop James Ussher, a seventeenth-century Irish-born cleric of the Church of England, insisted that the world began precisely in 4004 B.C. (and probably in the morning), and Isaac Newton cautiously expected that it might end around 2000 A.D. (we hope he was wrong).4 Such views linked the study of history to the highest religious purposes and gave the historical process a teleology in which every event in history connected in some way to a central divine story. The influence of the Christian time schema remains in the Western calendar, which marks all time according to the benchmark of the birth of Jesus; time is either B.C. (“Before Christ”) or A.D. (“anno Domini,” Latin for “in the year of the Lord”). Alternative forms such as B.C.E. for “Before the Common Era” do not really challenge the Christian dating system.

Christian historians wished to link all previous history to one universal story, informed by their faith. They explained events by reference to God’s direct divine intervention. Late-sixteenth-century Spanish chroniclers, for example, attributed the Spanish victory over the Muslims at the Battle of Lepanto in 1571 to the appearance of the Virgin Mary in the heavens. Only a few years later, Elizabeth I of England celebrated the defeat of the Spanish Armada, dashed by storms along the English coast, by issuing a medal that read: “God blew, and they were scattered.” Colonial American historians believed that God had delayed the discovery of North America so that Protestants could settle their part of the New World. These are not the sort of explanations of historical events that a student would now give to questions on the Graduate Record Examination.

Between the fifteenth and eighteenth centuries, the Christian scheme of history steadily lost credibility. Certainty and conviction about God’s purposes in human affairs gave way to growing doubts, made more subversive by the attacks of Enlightenment propagandizes. Under the accumulated weight of new knowledge about the ancient Greeks and Romans and peoples in distant lands, the historical facade of the Christians cracked. A new sense of historical time emerged, thanks in part to the promise and example of breakthroughs in science. By the 1740s, when one of Newton’s once close associates went about the philosophical societies talking up the end of the world, people thought him to be a bit dotty.

Europeans in the seventeenth and eighteenth centuries began to develop what is now called a historical consciousness—that is, an appreciation of how the passage of time changes institutions and renders past societies strikingly different from contemporary ones. The study of classical models helped initiate this breakthrough in thinking about the past. As Renaissance scholars learned more and more about the ancient world in their quest to model themselves on ancient examples of politics, law, and literature, they discovered that there were actually enormous and unbridgeable differences between classical institutions and their own.

In England during the seventeenth century the scholarly interest in antiquity acquired a practical urgency when the open hostility between king and Parliament ended with King Charles I’s execution. Witnesses record that a long, anguished moan rose up from the crowd when the severed head of the king was displayed. No longer obedient subjects, the regicides had to find another basis for public order than that of the divine right of kings. They looked to the histories of Athenian democracy and the Roman republic to supply a new model for political action. An avid interest in classical republicanism fostered a deepening awareness of how social institutions accommodated the specific needs of people at a particular time and place. Having put themselves beyond the comfort of habitual obedience and customary usages, members of England’s upper class also encouraged the study of Parliament and the common law, creating a new body of historical knowledge about England’s ancient constitution.5

Under the pressure of these various changes, the turning points of sacred history eventually gave way to a secular, linear periodization of ancient, medieval, and modern, which still dominates history writing today. Progress in this world replaced salvation in the next as the goal of human participation in time. The movement toward the modern, rather than the fall from God’s grace now defined the direction of history. It is hard to imagine a more fundamental reorientation of the human place within time.

Language itself reflected these monumental changes. The English adjective “modern” first came into usage at the end of the sixteenth century. Derived from the Latin word modo for “just now,” it referred to the present or recent time as opposed to the remote past, but soon came to mean as well new-fashioned, not antiquated or obsolete. In other words, in the seventeenth and especially in the eighteenth century, “modern” came to mean better. Historians began to call their age modern so as to distinguish it from what came before. The Middle Ages, a term which first came into use at the end of the seventeenth century, pointed, as the term suggests, to the period between the ancients and the moderns. By implication, the Middle Ages were less advanced than the modern period; they were, as the French Enlightenment philosophe Condorcet said, a period of “the grossest ignorance extending over all nations and all occupations.”6 With the spread of the idea of progress, the modern period became the standard by which the past was judged. Even the ancients, who had long served as models in almost every field of learning, now seemed surpassable if not actually inferior. The new science, in particular, had shown this to be true. If the laws of human history could be understood, time would bring progress, not decline.

The transformation of Christian into secular time was not just a mental exercise. Better material conditions affected how people felt about the future (though they did not yet have opinion surveys about consumer confidence!). As chronic food shortages and periodic famines gave way late in the seventeenth century to agricultural improvements and then to a new industrial order, prosperity and growth seemed not only possible but permanent, even if they depended on the misery of slaves or workers. The fixed material limits of the medieval period had been conspicuously vaulted, and contemporaries asked themselves how this had happened. Sustained innovations shattered that old sense of social life endlessly repeating itself with little variation—at least for those men and women who benefited from the changes.

In a mood of newly aggressive confidence, eighteenth-century historians began to write a story of improvement and then of progress. In their story of progress, a major reversal occurred. Optimism about the prospect of steady amelioration of the human lot in this world displaced pessimism about the inexorable decline in the human condition since the Garden of Eden. For elites, the Christian framework of time no longer seemed relevant to natural or human history. The moderns had come to seem smarter than the ancients while simultaneously the old could now be “classified.” In the same spirit, British elites developed the notion of “classics” in music which could be enjoyed because of their distance from the modern and the contemporary.7

In eighteenth-century Scotland, a remarkable group of philosophers and scholars, numbering among others Adam Smith and David Hume, took upon themselves the task of analyzing how these changes had come about—how, for example, one could explain the wealth of nations, to echo the title of Smith’s famous work. Answers to questions about the transformative material changes in eighteenth-century Europe took the form of conjectural or philosophical history—a reasoning from what was true of the present back to the conditions that must have prevailed at the dawn of history.8

The writers of the Scottish Enlightenment came up with a four-stage theory of social development. In their view, human society passed in succession from domination by hunters and gatherers to shepherds to farmers to merchants. A number of important conceptual breakthroughs accompanied this historical sociology. The Scottish writers observed that human beings, acting within these different moral and material contexts, like those limiting the food supply of hunters and gatherers or the mobility of farmers, produced patterns of social interaction best described as developments rather than mere changes. Probing for the causes of these processes, they further elaborated the notion of unintended consequences, the most famous being that of Smith’s invisible hand of the market, in which men and women bought and sold in pursuit of their own profit, but, constrained by competition, unintentionally enhanced the productivity of the whole society. As the term “conjectural history” implies, these historical schemes were conjectures based more upon deductions from a few known facts than on evidence from an abundance of empirical findings, but they undergirded historical consciousness in important ways.

The philosophes of the Enlightenment confidently argued that if human beings could develop science and comprehend the laws of nature, then they could also remake society, politics, and every other realm of human life. Progress was possible, they insisted, because humans were basically good, not fundamentally evil as Christianity had taught. John Locke’s depiction of the human mind as a blank slate waiting to be written on made it possible to believe that education could transform any human being and hence any society. His widely influential views encouraged the belief that social engineering could mold a new kind of individual. Not coincidentally, the modern idea of revolution took shape at this time.9 Revolution no longer meant a cyclical return to a point of departure, as in a revolution of a planet around the sun, but rather came to mean a jump forward into the previously unknown, an experiment in Lockean social engineering. Revolution in this sense depended on an idea of the modern. Arguably, modernity first took shape in late-seventeenth-century England where the institutions of monarchy and church were irrevocably weakened. Modernity and the origins of democracy in the West are thus implicated one in the other.

The kind of schematic history that we are telling here raises an important issue that is worth lingering on for a moment or two. Because in this book we use the language of development deployed in the eighteenth and nineteenth centuries, we run the serious danger of giving our own story a very teleological cast: the history of history could only move forward, we seem to imply, when the supposed defects and deficiencies of past conceptions were recognized and corrected. By definition, the defects and deficiencies are those characteristics that dropped out of history as it became a modern, academic discipline. Such an account is bound to appear teleological in retrospect, if only because we are trying to tell a long story in a very short space. So we want to emphasize as strongly as possible that the story only seems to be so purposeful from our perspective of hindsight. Along the way, the direction was far from obvious to contemporaries (and even now, it is not clear how history will develop in the future). In this short space, we also necessarily omit most of the bitter conflicts that swirled around the men (and few women) who invented the academic discipline of history. Every step forward was contested and negotiated; we tell of outcomes more often than of those processes of contestation and competition.

The development of the new idea of progress did not leave much room for appreciation of the past on its own terms. In the heat of the cultural wars of the Enlightenment, many philosophies denounced history, especially of the Middle Ages, as the repository of all that was cruel, barbaric, and backward. One school primer from the time of the French Revolution, for example, labeled history “the registers of the unhappiness of humanity.”10 The English feminist Mary Wollstonecraft believed that “brutal force has hitherto governed the world,” and in her view, the science of politics was still in its “infancy.”11 History was the nightmare of past superstitions that science and social engineering might transform. Progress aided by science and technology meant leaving the past behind like outgrowing an unhappy childhood.

Every decisive cultural movement produces its own reaction, and the Enlightenment was no exception. Already in the midst of its triumph, some scholars, artists, and poets began to champ at the bit of a reason that seemed arrogant and impervious to the darker, more exciting, emotional, and creative sides of life. The Romantics, as they were soon known, valued emotion over reason, an almost religious response to the wonders of nature over scientific detachment, and the mysteries of history over the brash efforts to escape from it. Some Romantics even sought refuge in an idealized medieval world, seeking out old castles, the more ruined the better, and in the process inventing a modern sensibility known as the gothic.

Among the most influential of the Romantic scholars of history was Johann Gottfried Herder. Arguing that each culture and every historical epoch had to be understood on its own terms, Herder urged historians to adopt a posture of respectful deference toward the past. “Each age is different, and each has the center of its happiness within itself,” he insisted. Even the Middle Ages possessed “something solid, cohesive and majestic.” This insistence on the integrity of the past, on its right to be taken on its own terms, eventually enhanced the confidence of historians. Ironically, despite Herder’s insistence on the difference between cultures and epochs, his position also made time itself into an even more universal continuum in which each epoch had its own role to play, a role that remained to be discovered by the historian.

History, Herder said, revealed the soaring spirit of ever-youthful nations and their irrepressible cultural differences. Herder coined the term “nationalism” and made the nation the unit in which time marches forward. In a vision that was both Romantic and deeply nationalist, Herder underlined the need for a national folk identity: “Let us follow our own path…let men speak well or ill of our nation, our literature, our language: they are ours, they are ourselves, and let that be enough.”12 A sense of one’s history, Herder maintained, should be celebrated because it shaped national and ethnic identity.

From the end of the eighteenth century onward, personal identity was consequently linked to nationalism and required an elaborate ethnic heritage, even where none had existed before. All at once, seemingly, nations began to discover—or rediscover—themselves. The first official grammar for Russian, for example, appeared in 1802, the first Ukrainian one in 1819. Slovene, Serbo-Croatian, and Bulgarian all took shape as separate languages in the first decades of the nineteenth century. Everywhere, scholars rushed to discover literary and historical forebears who would give the nation a long lineage. Not surprisingly, history books, along with grammars, dictionaries, and the study of folklore, stood at the forefront of struggles for national identity and independence throughout the nineteenth and twentieth centuries. The invented community of the nation called out for historical grounding, even if it had to be essentially created for the occasion.13

The history of nations got its sanctification in Georg W. F. Hegel’s doctrine of historicism, which held that truth is rooted in history itself. History revealed truth, and nations were its carriers. The German philosopher lectured and wrote decades before Germany achieved national unity. His lectures were avidly followed by nationalistic students, even though his prose was difficult, even impenetrable. In Hegel’s inimitable prose, “History…has constituted the rational necessary course of the World-Spirit—that Spirit whose nature is always one and the same, but which unfolds this its one nature in the phenomena of the World’s existence.”14 In historicism, the truths of reason (Hegel’s “rational necessary course of the World-Spirit”) could not be discovered outside of history.

Hegel’s historicism reversed the usual relationship between philosophy and history. Until Hegel, all great thinkers worshiped at the altar of philosophy because it asked the important, eternal questions. Hegel insisted that philosophical truth itself was only revealed in history, and especially in the struggle of nations to define themselves. Time now enveloped thought. Only as history advanced, he claimed, could humans encounter truth. No one could escape history; progress depended on recognizing the direction of history and moving with it. Today many of Hegel’s ideas are considered quaint, anachronistic, biased, and even racist; he thought that Protestants were more evolved than Catholics in spiritual values, that the blacks of Africa had no moral sentiments or self-control, and that the state of Prussia alone had developed a real moral framework. Yet even the ability to judge Hegel himself depends on his sense of history as a developmental process. Critics think of themselves as seeing more and better than Hegel did because they have the benefit of more historical hindsight. In Hegelian terms, as history marches forward, it reveals more and more of the meaning implicit in it and moral judgments improve accordingly.

Even though nothing could have been further from his intention, Hegel opened the way to relativism, that is, the idea that truth depends on historical circumstances. If truth is revealed over time, then any truth, moral, scientific, or political, also changes over time and is never permanent. What seems to be true today may not be true in the conditions of tomorrow; what is true for some people is not true for others. Thus, even as Hegel’s views lent great prestige to history, now conceived as an essential framework for philosophy, they also created potential problems for the idea of historical truth itself. Were there no absolute moral standards that transcended the particularities of time and place? Was the role of historians simply limited to explaining how previous people had thought and acted without passing judgment on those thoughts and actions?

Although historicism prepared the way for relativism, none of the leading figures of nineteenth-century European intellectual life embraced either moral or epistemological relativism before the 1880s. Arguably the most influential thinkers of the nineteenth century, Auguste Comte, Charles Darwin, and Karl Marx all believed in the absolute truths of science. History revealed scientific laws that could be discovered once and for all. Each of them in a very different way helped to take history down from its Hegelian spiritual shelf by making it entirely secular, scientific, and explicitly evolutionary. Comte insisted that history revealed scientific laws. Darwin offered the most compelling scientific model of such a law in his theory of natural selection. Marx proclaimed himself the discoverer of the equivalent laws in human history. Contemporary Westerners still live under the influence of—or in revolt from—their ideas.

The French sociologist Comte coined the term “positivism” in the 1830s to capture his view of the scientific status of historical laws. Inspired by heroic science, Comte maintained that progress in all knowledge as in science depends on developing general laws out of direct observations of phenomena. He believed that human history had passed through a theological stage (childhood) and a metaphysical stage (youth) and was now entering the “positive” stage (adulthood) when events would be explained by scientific laws. “It is time,” Comte insisted, “to complete the vast operation begun by Bacon, Descartes, and Galileo, by reconstructing the system of general ideas which must henceforth prevail amongst the human race.” Comte was not excessively modest about his aims. He provided all the details of administration for a new Western society, including a new calendar, festivals, worship of new positive saints, and new churches. He predicted that he would one day preach the gospel of positivism in Notre Dame Cathedral.15

Comte himself was not much interested in history as practiced by historians, and his own writings were very speculative and theoretical, but his theories had a great impact on historians. Positivist historians, as they came to call themselves in the nineteenth century, left out the speculative parts of Comte’s own philosophy and concentrated instead on his prescriptions for method. They insisted that historians must begin with the documents and the facts they revealed and then develop their generalizations on a scientific model. Careful collection of documents, patient study and comparison, and the gradual accumulation of information would itself reveal the laws that determined historical development. Positivism, in one form or another, dominated the social sciences until well into the 1950s.

Darwin based his law of natural selection on the patient amassing and comparison of facts so beloved of the positivists, but when it came to public attention in 1859 it had the shattering impact of a bombshell. The full title of Darwin’s book suggests its potential for controversy: On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life. Constant bloody, desperate struggles for the survival of each species marked the passage of time in Darwin’s model of natural history. In the midst of all this strife, operating almost on another plane, biology randomly produced continual mutations. The species that prevailed in this situation were the ones lucky enough to have developed in ways that assisted their survival. The order and harmony of Newton’s universe did not hold in biology.

Darwin insisted on the accidental nature of the developmental process. Species survived because they proved to be the fittest, but they had no control over the process of mutation that made them fit in the first place. Unfortunately, Darwin was immediately misunderstood on this crucial point, and the idea of the survival of the fittest was soon taken up by racists, imperialists, and what became known more generally as social Darwinists. Although Darwin referred to pigeons and not people when he used the word “race” in his title, others used his work to explain why Europeans colonized other parts of the world (they were the superior race), why war was good (the death of the loser was “natural”), and why Anglo-Saxons should form their own organizations to rule the world. Eighty years later, Nazi racial ideologists would construct a rationale for genocide out of the same themes. Sometimes no matter what the intention of the author, books are like seeds thrown in the wind, settling in unexpected places and sometimes sprouting in stunted or misshapen form as a result.

The law of natural selection of the fittest ignited a cultural war in Darwin’s time (one which continues today in the United States) between the promoters of secular science and the defenders of traditional religious values. Many hailed Darwin as the Newton of biology, and supporters viewed the evolutionary debate as nothing short of a new Reformation. By substituting natural selection for Providence, Darwin undermined the Christian belief in a divine plan and the special place of human beings in the universe. Cold, random chance ruled nature, according to Darwin, not a beneficent design. Even human beings, he argued, had not always been the same; as a species, they had probably evolved from primates. Humans, like apes, bees, and lizards, were subject to the pressures of evolution. Outraged critics protested that Darwin had reduced all humanity to the level of beasts, and opponents shouted “monkey, monkey” at speakers who defended Darwin’s principles.

Where Hegel saw history as revealing the truth of the human spirit and Darwin detected the operation of the laws of nature, Marx found truth in the material laws governing human society. Marx aimed to understand the changes wrought by the Industrial Revolution. At the base of every society lay its economic mode of production, he believed, and that in turn shaped everything in human history, including politics and culture. The mode of production determined in particular the nature of social relations and class struggles within each society. The transformation of one mode of production into another—from feudalism to industrial capitalism, for example—propelled history’s forward movement. With the passion of a revolutionary, Marx propagated his discoveries. He proclaimed material forces, often expressed as a class struggle between the haves and the have-nots, to be the engine of historical change—the equivalent, in other words, of Darwin’s principle of natural selection.

Exiled from continental Europe for his revolutionary activities, Marx sought his historical laws not in the laboratory of nature but rather in the archives available in the British Museum in London. There, under its magnificent rotunda, he burrowed his way through mounds of documentation about the workings of industry and capitalism. Never modest, he aimed to change the course of history by understanding its laws, unifying the Enlightenment, the French Revolution, and the Industrial Revolution into the first complete theory of history as a secular and materially based human process. Inspired by Hegel, but substituting matter for the World Spirit, Marx believed that human reason could penetrate the material meaning of history, and in particular the laws of the development of capitalism. These laws would lay the foundation for the revolutionary transformation of capitalism into communism. As Engels put it, “Just as Darwin discovered the law of development of organic nature, so Marx discovered the laws of development of human history.”16 Marx was convinced that if the victims of history understood the laws of historical development, and especially the laws of capitalism, they would learn how and when to seize control over the present and the future. There had been revolutions before Marx, but with his theories revolutionaries could imagine themselves to be scientists.

Marxism captured the imagination of intellectuals and ordinary people too because it made sense of the brutal transformations wrought in economic and social life by the process of industrialization. Marxism also offered a theoretical explanation for the whole of human history as well as for each particular epoch within it. The idea of progress, historicism, and a scientific history seemed to come together in Marxism. Here was a vision of history informed by heroic science that offered a concrete social and economic model of the meaning of progress (the triumph of one mode of production over another), that sought the laws of change within the process of history itself (and thus was historicist), and that claimed a scientific status for the inexorable workings of social laws (and thus was determinist). Marxism also seemed to make revolutions inevitable and endorsed their benefits.

You do not have to be Hegelian, Comtian, Darwinian, or Marxist in your views in order to appreciate this series of breakthroughs in the conceptualization of human time made by the last third of the nineteenth century. Ever since then, most educated people in the West have been in some sense historicists, for they believe that their lives, both individual and collective, take shape in time, now conceived as a universal, secular continuum. Westerners cannot imagine their societies without this secular history of themselves. The schools teach it from the early years, and one of the first things children learn from their parents is their own place in this history. Colonized people learned it from Western colonizers; they then proceeded to rewrite their parts in the scripts.

The current debates about history simultaneously depend upon and challenge the Western mastery of time. Multiculturalism as a movement, for example, depends very much on historicism, for it rests on the belief that every epoch (and by extension every people) creates its own form of historical truth. It is in many respects very Herderian, even Hegelian. Yet multiculturalists and other critics of modernity also question whether the Western universalizing, standardizing sense of time is adequate for the present age. They object to the effacement of alternative versions of time found in other cultures or in oral traditions. They are suggesting, in effect, that international and national units of time be displaced by something more specific to each group’s identity.





The Mastery of Facts



The theorists of modern history like Hegel and Comte provided an intellectual rationale for history’s importance. But writing history involved more than this intellectual rationale; it required as well a mastery of the facts, that is, a knowledge of the standards by which historians sifted facts from legend. This process of sifting had often been haphazard or at best an individual affair. Historians became professionals and greatly extended their influence when history became an academic discipline in the nineteenth century with commonly accepted standards of inquiry and verification. Using archives and libraries as their laboratories, the new professionals embraced the scientific model to legitimize their standards.

In the wake of Hegel’s revalidation of history in the 1820s, historians in the many German states began to develop professional standards for historical work. They were not the first to insist that history should be truthful. Thucydides, for example, had criticized his Greek predecessors for failing to distinguish between fact and legend, and the humanist historians of the Renaissance took special delight in unearthing historical forgeries perpetrated by church authorities for their own purposes. However, from the point of view of the self-proclaimed scientific historians of the nineteenth-century German universities, none of these previous efforts had done more than scratch the surface of the scientific model.

If Newton could hold a mirror up to nature and explain its workings, then historians ought to be able to do the same for the past. To be scientific, consequently, history needed something like a laboratory and something like physical evidence. The seminar rooms and archives where university scholars taught and did research became the laboratories of history; historians sought their evidence amid the dust of actual documents and other traces left by the past. Through the seminar, invented in the 1830s by a German professor of history, Leopold von Ranke, the master teacher taught the techniques of reading and dissecting historical documents. Students learned to compare the documents rigorously; newly opened state and church archives became places where truth might be found through an interrogation of document after document. Ranke’s students (all men) saw themselves as “intimate disciples” of the beloved master. “He would break into joyous laughter,” one of them reported, “when he succeeded in destroying a false tradition or in reconstructing events as they occurred.”17 It is hard to imagine that quality of enthusiasm in most history classrooms today.

When professional historians wrote according to the scientific model, they employed the distant (not laughing) voice of the omniscient narrator, familiar from the realist novels of the nineteenth century and modeled on the voice of the scientists in their laboratory reports. The omniscient narrator stood above superstition and prejudice to survey calmly and dispassionately the scenes of the past and tell a truth that would be acceptable to any other researcher who had seen the same evidence and applied the same rules. In this way, with science as their model both in terms of research and writing, the German universities trained the first professional historians and soon exported them to the United States. They transformed American classrooms into seminars where every student became a seeker, an imagined re-creator of the past.

In his very first book, published in 1824, Ranke insisted that historians should give up the still-dominant view of history as a collection of moral instances teaching lessons through example (as in the current practice of citing the examples of appeasement at Munich or the failures of the war in Vietnam). “To history has been attributed the office to judge the past and to instruct the present to make its future useful…. at such high functions this present work does not aim—it merely wants to show how things really were.”18 “How things really were,” that search for a scientific mirror of the historical past, soon became the motto for a scientific and objective history. Historians had to learn to overcome their prejudices and present-day interests in order to get at the truth of events in the past. Each historical epoch had to be taken on its own terms, as Herder had insisted.

Ranke’s own histories were hardly disinterested. He wrote history in support of German nationalism—becoming official historiographer for the Prussian state in 1841—and believed that history revealed the hidden hand of God. Yet his techniques for training historians were eagerly taken up by professors of history in other countries who had quite different views of the meaning of the past. Ranke started his seminar in his study at home and trained two generations of men (one of his students was the crown prince of Bavaria) in the need to approach documents in a critical or hermeneutical spirit. The emphasis on professional training remained even when Ranke’s own interpretations of history fell out of fashion. In recognition of his international influence, the American Historical Association named him its first honorary member when it was founded in 1884.19 He was the international model for the master historian, and his name long seemed synonymous with the goal of objectivity.

By the 1880s, historians had taken several steps toward forming an organized professional discipline in Europe and the United States. Although amateurs still wrote history and even dominated the early years of the American Historical Association, regular forms of training in the classroom and official organizations to oversee standards had both been established. Professionalization went hand in hand with the project for a scientific history; professionalization was supposed to guarantee a scientific attitude of detachment. To be a professional meant being certified (through a higher degree) as having learned the self-discipline necessary to go beyond self-interest, bias, prejudice, and present-day concerns. This scientific professionalism was graphically demonstrated by the founding issue in 1876 of La Revue historique, which explained that the new journal would demand from its contributors “procedures of exposition that were strictly scientific, where every statement must be accompanied by proofs, by references to sources and by citations.”20 If one failed to use such methods, one could (then and now) both publish and perish.

Historians of the end of the nineteenth century conceived scientific history as objective because it was not concerned with philosophy or theory. The facts got priority. In words that seem to come out of the mouth of Mr. Gradgrind in Charles Dickens’s Hard Times, a French historian exhorted his colleagues at the opening session of the First International Congress of Historians in 1900 (the meeting itself being another sign of professionalization):





We want nothing more to do with the approximations of hypotheses, useless systems, theories as brilliant as they are deceptive, superfluous moralities. Facts, facts, facts—which carry within themselves their lesson and their philosophy. The truth, all the truth, nothing but the truth.21





Where Gradgrind’s facts signaled a cold and oppressive view of a world without emotion, the historian’s facts stood in the speaker’s mind for a kind of liberation. An amazing turnabout had taken place. History had long been considered the servant of philosophy; now historians aimed to sever their discipline from philosophy in the interest of attaining scientific results. Facts came before philosophy; theory was a “useless system.” History had to be autonomous as a discipline if it was to be objective and scientific. To this day, blood pressure rises among some historians at the very mention of the word “theory.” Chapter 6 will explore some of the reasons why this might be so.

By the beginning of the twentieth century, the new professional historians had developed a scientific model of their craft that set it apart from philosophy or theory. They had been influenced by the insights of philosophers and theorists such as Hegel and Comte, but they had no desire to follow the same philosophical and theoretical veins in their own work. They believed that history could contribute to progress only if historians behaved like scientists. Just as Newton’s law of gravitation applied in every country and culture, so too good history should be able to transcend national differences. As Lord Acton explained to his collaborators on the Cambridge Modern History, “our Waterloo must be one that satisfies French and English, Germans and Dutch alike.”22 Although historians differed about just how scientific history could be and about the role of generalization or general laws, history went its way henceforth as a discipline almost wholly separated from philosophy. The philosophy of history was and still is a branch of philosophy, not history.





Imperialist, Scientific History in the West



Historians founded an independent, autonomous discipline by developing new notions of time and new professional codes of conduct. These developments took place in the context of intense intellectual and political struggles, pitting secularizers against Christian clergymen and then professional academics against popularizers, amateurs, and various forms of true believers. The very idea of a historian transcending his or her prejudices to write a scientific history of the march toward modernity depended as a political project on the Enlightenment sense of the modern and of progress. Once established, however, those political origins were often forgotten. Over time, professional historians set up their own kinds of absolutism in the name of universal (synonymous with Western) science and progress, and they set out to incorporate the whole world into their schemas of interpretation. We call this ambition imperialist in recognition of its universalizing and globalizing impulse. We do not imply that individual historians always, or even most of the time, wrote in support of imperialist policies.

Despite its many varieties, professional history in the twentieth century has been usually written under the sign of “modernization,” the general process by which the West, defined as the paradigmatic model, and then the rest of the world became modern. This can hardly be surprising, given that the idea of modernity has shaped the development of Western history ever since the eighteenth century. And history is far from alone in this emphasis. In the early decades of the twentieth century, as economics, sociology, political science, psychology, and anthropology each established their own autonomous spheres of inquiry, one main question guided research in all of them, as well as in history: how did the modern world come about, and what lessons does the Western trajectory toward the modern offer to the rest of the world? The operating principles of industrial markets or technology transfers, the forms of modern social and political interaction, the psychological effects of growth and differentiation, and the impact of rapid change on Third World peoples—all these can be seen as derivatives of the main question about modernization.

Two great social theorists of the early twentieth century, Max Weber and Emile Durkheim, both wrestled with these questions and gave answers that are influential to this day. They sought alternatives to Marx’s analysis of modernization, but they started from the same Enlightenment standpoint as Marx: we are modern, and our task is to understand what that entails. In contrast to Marx’s insistence on modes of production, social struggle, and revolution, the German social theorist Weber underlined the synergistic effects of markets, states, and bureaucracies in integrating ever larger groups of people, while the French sociologist Durkheim emphasized the corrosive impact of increasing differentiation of functions, growing isolation of individuals, and the breakdown of community and guild structures. Whatever their differences of emphasis and interpretation, Weber and Durkheim were both much less optimistic than Marx about the long-term results of this process. Yet along with Marx, they helped give birth to the long-dominant modernization perspective, in which history is mustered to explain the origin of the forces that make the modern world modern.

Marx, Durkheim, and Weber inspired the three main schools of Western historical interpretation in the twentieth century: Marxism, the French Annales school, and American modernization theory. As the label suggests, Marxist history owes its origins to Marx’s own trenchant diagnoses of modernity. Durkheim’s emphasis on the effects of long-term social processes can be seen in the French Annales (so named after its flagship journal) school’s interest in broad demographic and economic trends rather than in traditional political, diplomatic, or biographical accounts. American social-scientific models that developed in the 1950s and 1960s under the rubric of “modernization theory” (a special case of what we are calling more generally the modernization perspective) showed the impact of Weber’s comparative studies on the origins of modernity. Needless to say, all history writing in this century does not fit neatly into one of these three categories, and Annales school history and modernization models cannot be very easily divided between the legacies of Durkheim and Weber. Yet as general models for the goals and methods of history, these three lines of interpretation have been primary, especially since World War II.

Lumping Marxism, the Annales school, and American modernization theory together does run the risk of mixing apples and oranges, or perhaps even apples, walnuts, and broccoli, so different are the three in some respects. Marxism has influenced history writing since the 1870s, and in some places it has been directly associated with a ruling party. Only Marxism, moreover, ever achieved the dubious status of a recognized national and international orthodoxy. The Annales school took shape as a branch of French history just before World War II and then extended its impact internationally, but it—like Marxism—has remained relatively uninfluential in the United States. American modernization theory was the specifically American answer to Marxism, but it came directly out of American sociology and political science in the post—World War II period and never had much influence outside the United States.

What the three have in common, however, is at least as important as their considerable differences: all three were imagined by their adherents as universally applicable and scientific in method and thus all three helped foster a Western history that aimed to homogenize the study of all other places and times into general Western models of historical development. Whether historians emphasized class struggle (Marxists), broad demographic changes (Annales school), or the development of new networks of investment and communication (modernization theory), they expected their explanations to apply to the whole world, and they confidently set out to show that their models could work everywhere. Nobody escapes the modernizing process.

Marx offered the boldest, most provocative account of modernization with his analysis of changing modes of production and class conflict leading to revolution. In British and French universities in the 1930s and 1940s, some of the brightest young historians were attracted to Marxism and in some cases joined the Communist Party. In the postwar era, the best of them—Christopher Hill, Eric Hobsbawm, E. P. Thompson, and Albert Soboul—wrote books that shaped a generation or more of historical thinking. Their emphasis on “history from below” inspired the rejection of the traditional histories of political leaders, ideas, and institutions in favor of the social history of workers, servants, and the poor. History graduate students still learned the methods of Ranke in their seminars, but debates about Marxism and its relevance often fueled their passion for the subject.

Marxism had the most direct influence in Eastern Europe, because it was the official ideology of ruling parties in the Soviet Union and its satellites after World War II. In the Soviet-bloc countries, historians had to declare their allegiance to Marxism if they wanted to publish books and hold professional positions. The situation was much more complicated in Western Europe. There, Marxism might have remained a dry academic question (in the absence of successful revolutionary movements) had it not been for Hitler and the rise of fascism in the 1930s. For many Western intellectuals, only Marxism seemed to have enough ethical, political, and social clout to combat fascism, and they did not or would not see the dangers of the Marxism being put into practice in the new Soviet Union. Thus Marxist history found very different outlooks in Eastern and Western Europe. In the east, Marxism not only dominated but excluded all other options, at least on paper, while in the west, Marxism reemerged in the 1930s as an oppositional ideology.

In the United States, the impact of Marxism has been more diffuse and general than in either Western or Eastern Europe. Few American historians have written explicitly as Marxists, but Marxism has nonetheless forced historians in the United States to consider systematically the effects of capitalism on social and political conflict and to pay more attention to the historical fate of the lower orders. Many historians who reject the main lines of Marxism—the emphasis on inevitable revolution or the ubiquity of class struggle, for instance—still believe that history is fundamentally a material process in which economics shapes social, cultural, and political life. Even anti-Marxists were shaped by their interactions with the Marxism they encountered in their general education. The Annales school and modernization theory gained adherents in the West, after all, precisely because they were non-Marxist modes of historical explanation that still took the question of modernization seriously.

Marxists considered their history just as scientific as that of their competitors, if not more so. Western Marxists, in particular, maintained that Marxist history could be impartial even when it was motivated by a passion for change. One of the greatest socialist historians in the English-speaking world, R. H. Tawney, insisted in 1912, “If a man wants to do serious scientific work in any sphere, he must become impersonal, suppress his own fancies and predilections, and try and listen to reason speaking in him.”23 This was still very similar to the Rankean vision, and it is this impartiality that supports the ambition to subsume all history under the Marxist framework.

Many historians nonetheless rejected Marxism because they associated it with determinism and reductionism, i.e., with efforts to reduce all of history to material causes, thus overlooking the influence of ideas, emotions, personalities, and accidents. The association of Marxism with communism after the Bolshevik revolution of 1917 in Russia further tainted Marxism for many historians and even made some of them suspicious of any effort to explain history in terms of general laws or theories. The search for the correct historical laws seemed hopelessly mired in revolutionary politics. The ideological thrust of Marxist-Leninist history-writing in Eastern Europe can be seen in a speech of 1931 given by the Russian historian M. N. Pokrovsky, who described the tasks of the Society of Marxist Historians as “the unmasking of the bourgeois historians” (the historians of the West still influenced by capitalist ideology) and coming to grips “with its fundamental enemy in the period ahead—the deviationists” (i.e., those who deviated from the true Leninist line within Marxism). For him, this meant that history “must reveal and submit to a merciless Marxist-Leninist analysis.”24 It was precisely this image of submission to an ideology that troubled many historians in the West.

The French Annales school offered an alternative to Marxism in the postwar period, yet it relied on an equally and perhaps even more ambitious vision of history. French historians of the school tried to solve the enduring problem of history’s relation to the other disciplines by developing a concept of “total history,” the none-too-modest notion whose very name conveys the design to comprehend everyone’s history in one general model. In total history, historians would incorporate the methods of all the other social sciences in one great project of synthesis. History would be the queen of the social sciences by virtue of its ability to assimilate everyone else’s methods and topics. Lucien Febvre explained the need for total history: “Man cannot be carved into slices. He is a whole. One must not divide all of history—here the events, there the beliefs.”25 Annales history had to be “total” if it was to respond adequately to the challenge of Marxism by developing an alternative model of a universalizing history.

The great systematizer of the Annales school was Fernand Braudel, who in the 1940s wrote his first great work while interned in a German camp for prisoners of war. Braudel developed an influential three-tiered model of historical explanation. Climate, biology, and geography in the bottom tier ruled over long-term population movements and economic trends. Social structures and patterns, more clearly subject to the fluctuations of the medium term (defined usually in units of ten, twenty, or even fifty years), constituted a second order of historical reality. Politics, culture, and intellectual life were viewed as a third, largely dependent level of historical experience. In a famous passage, Braudel likened the events of history so prominent in traditional accounts to “surface disturbances, crests of foam that the tides of history carry on their strong backs.”26 What mattered was not the quickly disappearing foam but the enduring factors of material life that made up the tides pulling the waves themselves. All of world history could be explained in terms of those historical tides.

The Annales model of total history resembled the Marxist paradigm, especially in the dominance ascribed to long-term economic developments over political and intellectual ones. But the Annales school deemphasized class struggle and modes of production and underlined the importance instead of underlying demographic processes. Annales historians insisted particularly on what Durkheim had called “social facts”—long-term processes such as population growth or contraction, price curves, harvest yields, tax receipts, and the like. These indicators could be studied through serial records and quantifiable methods that measured the ebb and flow of societies.

Under the leadership of Braudel, the Annales school developed a wide following in the 1960s, especially in Europe and Latin America. By the 1970s, the prestige of the school was worldwide; the International Handbook of Historical Studies published in 1979, for instance, included more index entries for the Annales school than for any other subject except Marx and Marxism.27 The Annales school’s emphasis on economic and social history soon spread even to the more traditional historical journals. By the early 1970s, economic and social history had replaced biography and religious history as the largest categories after political history in many conventional journals.28

The Annales school—along with Marxism—fostered the growth of social history in the twentieth century. Whereas nineteenth-century historians had made vague references to “the people,” social historians in the twentieth century sought to uncover the lives of ordinary people in all their richness. Ordinary people—peasants, workers, immigrants, for example—had been left out of traditional historical accounts because they did not make the political and military decisions for a whole society. By questioning the lasting importance of those political and military decisions and emphasizing instead the enduring demographic patterns—of marriage, childbearing, and death, for example—which shaped societies over a much longer term, the Annales school helped establish social history as a field of research.

American modernization theory, the third of the major schools of historical interpretation in the twentieth century, aimed to unify the increasing diversity of historical research in its own non-Marxist model of historical development. As defined by one of its early proponents,





there is a single process of modernization which operates in all developing societies—regardless of their colour, creed, or climate and regardless of their history, geography, or culture. This is the process of economic development, and…development cannot be sustained without modernization.29





In this characteristically circular definition, modernization and economic development were intimately linked; economic development was the key process in modernization but economic development could not take place without modernization, which was defined to include a shift from agriculture to industry, the rise of cities, the expansion of education, particularly in science and technology, and a host of concomitant intellectual and psychological changes. Many modernization theorists, following Weber’s lead, emphasized the role of intellectual and psychological changes in producing a rational and autonomous self that was essential to modernization more generally. What is most striking in the definition of modernization, however, is not so much its circularity as its aim to be all-encompassing. According to modernization theory, all developing societies, whatever their differences, were bound to go through a similar set of changes. This was universal history with a vengeance, with all of its imperialistic implications for non-Western societies.

Modernization theorists studied how the process came about in the past in order, in part, to develop models for understanding the Third World in the present. One of the most influential modernization models was W. W. Rostow’s takeoff theory of industrialization. Rostow developed a model of what he termed “industrial takeoff” based on the Western experience in the eighteenth and nineteenth centuries with the hope of applying it to non-Western societies. Focusing on Britain in the last quarter of the eighteenth century, he used mechanical notions of acceleration and force to describe the self-sustaining process of industrial growth that had itself been assisted by applied mechanics.

Modernization theorists generally emphasized the destabilizing impact of rapid economic and urban growth and its tendency to promote political violence in a variety of forms (actually their Durkheimian side, one example of the dangers of schematic categorization). One theorist explained, “The very fact that modernization entails continual changes in all spheres of a society means of necessity that it involves processes of disorganization and dislocation.” Social problems, group conflicts, and protest movements (the very things that were increasingly apparent in the 1960s) could all be explained as the strains of modernization.30

American historians did not need modernization theory to point them toward social history. In the first decades of the twentieth century—before the French Annales school had even taken shape—a group of American historians called the New Historians urged their colleagues to escape “from the limitations formerly imposed upon the study of the past” and include the widest possible range of sources in their analysis.31 The experience of democracy and diversity inevitably put “the social” on the agenda of historians. But without a theoretical model like Marxism or totalizing methods like those proposed by the Annales school, the new history in America ran the risk of increasing fragmentation. Modernization theory promised to subsume all this new research under one coherent model. For a time, it gained many adherents. In a general review of contemporary historical writing in the United States published in 1980, for example, modernization theory ranked in importance right alongside the Annales school, Marxism, interdisciplinary developments, specialization, quantitative methods, and social science and social theory.32

This list is suggestive, for it links the three dominant models of history in the twentieth century with the professionalization of history as a discipline, with its relationship to the other social sciences, and with quantitative methods. Like the Annales school, modernization theory offered the prospect of making history more like a social science, and it was often linked, like the Annales school, to the use of quantitative methods in historical research.

For their proponents, the systematic collection of quantifiable documents and the application of quantitative measures guaranteed the scientific status of history and held out the promise of a true universalization of method. Quantitative methods could be applied to any culture, any epoch, and virtually any historical question. They were thus ideally suited to the study of modernization across the world. Historians used statistics to prove the efficiency or inefficiency of slave economies, to develop models of family life in preindustrial and industrial times, and to trace the impact of European diseases on native populations in the New World. The more historians used statistical techniques, it was hoped, the more their discipline would resemble science itself. Quantitative methods seemed ideal for ensuring detachment and impartiality, for letting the facts speak for themselves, in short, for mathematizing history. Thus the use of quantitative methods enabled Western historians to make even bigger claims for the purview of their discipline.

Despite its initial promise and its association with quantitative methods, modernization theory’s direct influence proved to be short-lived. Just as it had risen on the wave of Third World tumult in the aftermath of decolonization in the 1950s and 1960s, so too it then fell into disrepute in the wake of the Vietnam War. In the United States modernization theory came under attack for a variety of reasons. Some historians found it inherently ahistorical because it was based on sociological theorizing. Others criticized it as ethnocentric because it used development in the West as a standard for judging non-Western societies and cultures. In addition, modernization theory came under fire because it was prominent in strategic studies undertaken during the Vietnam War. As a concept it was tarred by the brush of American efforts to intervene in Third World politics.

For all these reasons, modernization theory receded into the background and now claims few dedicated adherents in historical circles. Yet despite the decline of modernization theory as a model, the questions that it posed remain as vital as ever and continue to exert a profound influence on historical study. The mere existence of journals such as World Development and Comparative Studies in Society and History shows that many scholars continue to seek lessons in the modernization of the West for current-day economic and political development. In the 1990s historians and social scientists emphasize the differences between the West and other areas of the globe, rather than assuming the operation of a universal model, but they still take Western development as a fundamental starting point for comparison.

Although modernization theory declined in influence, the belief in a scientific history and the idea of a total history remained powerful until very recently. The appearance of computers made quantitative methods even more attractive and held out the prospect of a rapidly accumulating store of knowledge. Moreover, knowledge of the world seemed crucial to success in the continuing Cold War, and the American government consequently funded new area studies programs (South-east Asia, South Asia, Soviet Union and Eastern Europe, Latin America, etc.), study in foreign languages, and research in history about every corner of the globe.

All of this work rested on the principles that had evolved since the mid-nineteenth century: a modern, scientific history could incorporate every place on earth into one secular universal story with the aim of understanding the patterns of development. Even though most individual historians no longer aimed to tell the whole universal story themselves in the manner of Hegel or Marx, history as a discipline depended on the belief that professional historians were writing pieces of that story. Getting the story right would help push forward the process of modernization (and progress) itself. As subsequent chapters will make clear, in the United States every element of this vision has now come under attack, raising questions about the future of history itself.

Before turning to that story of challenge, however, it is important to recognize the remarkable power of the notions of impartial science and scientific history in the service of modernization. The heroic image of an unprejudiced, dispassionate, all-seeing scientific investigator seemed to promise not only unparalleled material improvements through science and industry but also the end of superstition, fanaticism, and all other forms of intellectual and political absolutism. By developing the modern concepts of historical time as standardized and universal and of the role of the historian as master of the facts of everyone’s history, historians were able to set themselves new tasks. They told the story of progress toward the modern, of history as emancipation from the darkness of the past. Their history now had a meaning deeply implicated in the modern world. Despite the horrors wrought by modern warfare and technology, most historians continue to embrace modernity as the only alternative to the ignorance and relative poverty of most “traditional” societies.

In telling history “as it really was,” unencumbered by interpretations of divine will or recourse to the Bible, historians believed themselves to be facilitating progress toward the modern. Historians thus helped establish a distinctly Western mastery, not only of time and facts as universal entities, susceptible to study by any impartial investigator, but also, eventually, of everyone else’s history. The social history of workers, slaves, and immigrants and the histories of Third World peoples could all be incorporated into the dominant Western models of historical development, whether in the form of Marxism, the Annales school, or modernization theory. These models were all imperialist in their aim to encompass everyone. At times, they served the purposes of Eastern-bloc or Western-bloc political imperialism—and thus the Cold War—as well. Some Marxist history helped bolster Soviet-style communism; some modernization theory directly served U.S. interests abroad; and the Annales school seemed to offer a third path with the same general result, Western (but in this case Western European) mastery. The next chapter will show how these new notions of history worked themselves out in the American national saga, a saga informed by the belief in a people’s unique suitability for progress and for modernity.