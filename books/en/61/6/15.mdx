---
---
---
title: CHAPTER 15 FUTURES
---






This book started out examining very large structures and huge timescales. But its focus has narrowed—first to a single planet, then to the history of a single species, and finally to a single century in the history of that species. Now we must move back up the temporal and spatial scales once more as we look toward the future.





THINKING ABOUT THE FUTURE





We are all in a situation that resembles driving a fast vehicle at night over unknown terrain that is rough, full of gullies, with precipices not far off. Some kind of headlight, even a feeble and flickering one, may help to avoid some of the worst disasters.





It may seem foolish to discuss the future. After all, the future really is unpredictable.

It is not just that we don’t know enough. Some nineteenth-century scientists believed that reality was both deterministic and predictable. They thought that if we knew enough about the position and motion of everything around us, we could predict the future with great precision. It is now clear that this is not so. Quantum physics shows that it is in the nature of reality to be unpredictable. At the smallest levels, reality has something fuzzy about it. There appears to be a limit to the precision with which we can measure the movements of subatomic particles. It is as if they were in some sense smeared out over space and time, so that the best we can do is to estimate the probability of their being at a particular place at a particular time. This type of unpredictability is often described as chaos, because chaos theory has shown that billions of tiny uncertainties can accumulate through long chains of causation until, in the large-scale world that humans occupy, they create considerable large-scale unpredictability. In the 1990s, rigorous mathematical proofs found that chaotic behavior is more than a matter of ignorance or imprecision: it is just the way things are. Even if changes take place according to precise, deterministic rules, we can never know the starting point of change with enough accuracy to forecast its future course exactly. Thus, even if reality is deterministic, it need not be predictable.





Figure 15.1. Earthrise as seen from the Moon. This famous photograph was taken from Apollo 8 in December 1968. It has become a powerful symbol of our growing awareness of human unity and fragility. William Anders, one of the three astronauts on the mission, probably actually took the photograph. In a 1998 interview, he said, “All of the views of the Earth from the moon have led the human race, and its political leaders, and its environmental leaders, and its citizenry, [to] realize that we’re all jammed together on one really kind of dinky little planet, and we’d better treat it, and ourselves, better, or we’re not gonna be here very long.” As Fred Spier has pointed out, the Earthrise photo also provides an ironic symbol of the fragility of human maps of reality, for the accounts by the three astronauts of who took the photograph, and when, are utterly contradictory (Fred Spier, “The Apollo 8 Earthrise Photo,” 2000 <http://www.i20.uva.nl/inhoud/gig/Apollo%208%20US.pdf> [accessed April 2003]). Photo courtesy of NASA.



But there is a second kind of uncertainty. Understanding how a particular object works may not help us predict its behavior when it is combined with other objects into a larger system. Interacting systems with different elements appear to function according to emergent rules that we cannot always deduce simply by knowing how their components work. Understanding hydrogen and oxygen does not tell us much about water, which is formed by their chemical combination.1 Ricard Solé and Brian Goodwin observe, “With chaos, it is sensitivity to initial conditions that makes the dynamics unpredictable. With emergent properties, it is the general inability of observers to predict the behavior of nonlinear systems from an understanding of their parts and interactions.”2

We have seen both types of unpredictability at work in evolution and in human history. Many possible futures are compatible with the same rules of natural selection or cultural change. So change is always, to some degree, open-ended. There really is a difference between past and future, which makes prediction a dangerous game. Peter Stearns reminds us how dangerous it is by listing some of the more spectacular failed predictions made in the United States in the twentieth century: “[E]lectronic impulses from a supersonic alarm clock enter your brain directly to wake you up (1955); electronic brains will decide who marries whom, making more happy marriages (1952); only 10 percent of the population will work, while the rest are paid to be idle (1966 and recurrently); within a few decades, communicable diseases and also heart disease will be wiped out (again, 1966, clearly a banner year for optimistic technologists).”3 For all these reasons, historians normally avoid considering the future entirely. R. G. Collingwood wrote, sternly: “The historian’s business is to know the past, not to know the future, and whenever historians claim to be able to determine the future in advance of its happening we may know with certainty that something has gone wrong with their fundamental conception of history.”4

Despite these cautions, we cannot entirely avoid the challenge of trying to predict. There are at least two types of situation in which we can and must attempt forecasts. The first is when we are dealing with entities that change slowly or simply. There are degrees of open-endedness, for even chaotic processes will generally confine their unpredictability within limits. Thus for some processes and at some scales, change is reasonably simple and fairly easy to anticipate. These are the types of change that determinists once thought were typical of all change. For example, chemists can normally foresee the exact result of mixing defined quantities of simple chemicals at particular temperatures. This does not mean that prediction is easy, but it is sometimes possible if we take enough care about it. When firing a canon, it matters greatly where the projectile lands; for a gunner, the mathematics of ballistics is worth mastering, because it may make the difference between winning and losing a battle. Deterministic thinking also works pretty well when change is slow. For such processes, the present moment appears to stretch out, reaching well into what we think of as the future. The rise and fall of a single breath may last only a second or two, but the rise and fall of a mountain may take millions of years. So we can say with some confidence that Mount Everest will be around in 1,000 years’ time.

It is also worth thinking hard about the future when we are dealing with complex processes whose outcomes matter to us and over which we have some influence. Choosing which stocks to buy and which horse to back at the races are good examples. These are not deterministic processes, so we cannot predict them with the confidence of a gunner. But they are not totally open-ended. If change is utterly random, it is a waste of energy to attempt prediction; tossing a coin is as rational as any other way of making decisions. But where there is even a slight element of predictability in systems that matter to us, it is worth thinking hard about what is going on—and such situations are all around us. In handling them, prediction becomes a game of percentages. Those who carefully consider the variables involved in these types of change may find, over time, that they predict with slightly more success than those who make no effort. Some gamblers do make money. In such situations, the effort put into prediction matters, and it matters profoundly. Animals constantly have to make predictions about the likelihood of, say, finding dangerous predators in a particular place. Those that predict best will survive, and those that don’t won’t; in this way, skill in such predicting eventually gets built into the genetic makeup of most species. Choices whose outcomes matter even though they are neither deterministic nor completely random surround us all the time. So it is not surprising that in all human societies, entire professions have been based on the making of such predictions—think of astrologers, stockbrokers, professional gamblers, weather forecasters, or … politicians.

Making predictions of these two kinds, and making them as well as possible, is something living creatures do all the time, whether they are eagles swooping for the kill or investors buying shares. Indeed, action is impossible without prediction. Properly understood, prediction is as inevitable as breathing.

In thinking about the future at the scales of big history, we face both types of prediction. This chapter will begin by discussing our near future, on a scale of about one hundred years. At this scale, change is complex and unstable, but we have no reason to think it is totally random. Besides, we have to predict at this scale because our predictions will affect our actions, and our actions will help shape the lives of our children and grandchildren. So, trying to predict the shape of the next century is a serious task. In the “middle future” a scale of several hundred to several thousand years, serious prediction about the future of our species is almost impossible. We have little influence over these scales, and there are too many possible futures. Our ability to predict is so limited that it is not worth putting much effort into the task. Yet when we shift to the remote future, to larger timescales and larger objects, such as whole planets, or stars, or galaxies, or even the universe itself, prediction becomes easier again. This is because at these scales, we are dealing with slower and more predictable types of change, so that deterministic thinking comes into its own once more. Even here, there is no certainty, but the range of possibilities narrows.





THE NEAR FUTURE: THE NEXT HUNDRED YEARS





“Things happened very slowly and we didn’t notice them at first,” Jean-Marie explained. “At the beginning of an illness, you don’t realize it can do you harm. It’s only when you can no longer walk that you realize you are really sick. When we saw that the land was dying, we knew we had to do something. But we didn’t know what to do.” [Jean-Marie Sawadogo, 55, head of a family living near Ouagadougo, capital of Burkina Faso]



What we now call the plains of Pheleus [Plato’s homeland in Attica], were once covered in rich soil, and there was abundant timber on the mountains, of which traces may still be seen. Some of our mountains at present will only support bees. But not so very long ago trees fit for the roofs of vast buildings were felled there, and the rafters are still in existence. There were also many other lofty cultivated trees which provided unlimited fodder for beasts. The soil got the benefit of the yearly “water from Zeus.” This was not lost, as it is today, by running off a barren ground to the sea. A plentiful supply was received into the soil and stored up in the layers of clay. The moisture absorbed in the higher regions percolated to the hollows, and so all quarters were lavishly provided with springs and rivers. To this day the sanctuaries at their former sources survive. By comparison with the original territory, what is left now is like the skeleton of a body wasted by disease. The rich, soft soil has been carried off. Only the bare framework of the district is left.





The scale of a single century is strategic because it will be shaped by people living today, and it will affect the lives of our children and grandchildren. It is the scale we must consider if we want to pass the world on in good shape to our heirs. Furthermore, the accelerating transformations of the twentieth century make it socially and politically irresponsible not to consider futures on this scale, for things may change very fast. Besides, at this scale, political will and creativity may count for as much as prediction. Thus our predictions may themselves shape the future. We must learn to step outside the modern creation story, and accept that we are the collective authors of its next chapter.

But prediction at this scale is extremely difficult, more like forecasting the weather than plotting the trajectory of a missile. To play this game of percentages well, we must look first at the large trends we have considered in earlier chapters, because these, like geological processes, are likely to continue at least some distance into the future. But we must also consider the possibility that these trends may be changing direction, or could take sudden, random turns. And we need to be disciplined in our thinking, in order to make our maps of the future as plausible as possible. The emerging discipline known as futurology, whose roots lie in attempts to forecast technological developments during the Second World War, has been dominated by attempts to model futures with a focus on technologies, military outcomes (as in Herman Kahn’s 1960 book, On Thermonuclear War), and ecological impacts (as in the models of Donella Meadows and her colleagues at the Massachusetts Institute of Technology, beginning with the 1972 volume The Limits to Growth).5 But despite the sophistication of some of these models, those who construct them, from stockbrokers to meteorologists, know that the best they can hope for is a slightly better percentage of right guesses than their rivals. So, the basic rules of serious futurology are (a) look for the large trends and analyze how they work, (b) construct models to suggest how different trends may interact, and (c) be alert for countertrends or other factors that might falsify or cut across the predictions suggested by long trends and simple modeling. Beyond that, all we can do is prepare for the likelihood that many of our predictions will fail. This may not seem much of a claim for futurology, but it is better than doing nothing at all, just as studying the form at a racetrack is better than tossing a coin. In the long run, you will end up with more money if you study the form.

Some of the trends described in the previous chapter, including the accelerating pace of change itself, are worrying. These anxieties have been captured well by Clive Ponting in his remarkable Green History of the World (1992).6 In the first chapter of that book, Ponting offers a striking parable for human history as a whole, drawn from the history of one of the remotest places on earth, Rapa Nui. That island lies in the Pacific Ocean, 3,500 kilometers west of Chile; the nearest inhabited place is Pitcairn Island, 2,000 kilometers to the west. Rapa Nui is known to Westerners as Easter Island because it was first encountered by Europeans on a Dutch ship, Arena, on Easter Day, 1722. The crew of the Arena found about 3,000 people living on the island in poor reed huts or caves. They seemed to be engaged in almost constant warfare over scarce food resources. All in all, it seemed a desperately impoverished place. Yet the visitors also found more than 600 huge stone statues, most more than 6 meters high. These were astonishingly elegant and beautifully carved, and many had heavy stone topknots (some weighing 10 tons) resting on their heads. Carving, transporting, and setting up these statues must have required considerable technical and managerial sophistication, but there was no sign of such skills among the Easter Islanders of the eighteenth century. Moreover, it was hard to understand how such an impoverished environment could have supported a society capable of such monumental construction. In the eighteenth century, the islands had only one species of wild tree and one wild shrub. (The wild tree went extinct in the twentieth century, but was later reintroduced from specimens kept in a botanical garden in Sweden.) The only source of animal foods appeared to be chickens, as the inhabitants’ lack of boats prevented them from fishing.

The puzzle of Easter Island has been partly unraveled using modern techniques, such as the study of pollen remains, that can help archaeologists reconstruct ancient environments and landscapes. What has emerged is a sad story. The occupation of Easter Island was one of the final phases in the settlement of the Pacific, the fourth world zone of the Holocene era. (It is not impossible that there was an earlier population, of South American origin, but this remains unproven.) Easter Island was probably settled about 1,500 years ago by a boatload of twenty to thirty migrants from the Marquesas Islands in what is today French Polynesia. The small size of Easter Island, and its limited resources, ensured that colonizing it would not be easy. The island is only 22.5 kilometers long and about 11 kilometers wide. There were no indigenous mammals, and fish stocks in the waters around it were limited. The settlers brought chickens and rats with them; they soon found that of the crops they were used to, such as yam, taro, banana, and coconut, only one, the sweet potato, would really thrive there. So chicken and sweet potato became the basis of their diet. The good news was that it didn’t take much effort to make a living from these basic foodstuffs. The island was well forested, and there were fertile volcanic soils.

Over time, populations increased, and a number of separate villages emerged, scattered across the island. Competition between the villages and their chiefs may have taken the form of warfare, but it also took a recognizably modern form: competitive monument building. From as early as 700 CE, villages began to erect large stone courtyards, or ahus, with statues on them. These may have been monuments to living or dead local leaders, as some certainly contain tombs. Similar monuments can be found in many parts of Polynesia, but none as grand as those built on Easter Island. As these societies flourished, material and political hierarchies developed, and the managerial and technological skills of the islanders increased. Many of the ahus appear to be aligned with the stars in ways that suggest detailed astronomical knowledge, something to be expected of a people descended from seafarers. The islanders may even have created a simple form of writing.

The main puzzle for archaeologists was to figure out how the carvings were transported and placed in position. The answer seems to be that they were carried on rollers made from tree trunks. By about 500 years ago, the population of the island had grown to perhaps 7,000 people, and competition between villages was fierce. The building and transportation of more and more statues meant that more and more trees were cut down—until, eventually, the last tree fell. Quite suddenly, the society collapsed. The abruptness of the cataclysm is apparent from the presence in the island’s main quarry of unfinished statues, half carved from the volcanic rock. The effects of deforestation were devastating, for wood was needed not just to transport the statues but also to build fishing boats and houses, to make nets and cloth (from fibers of the paper mulberry tree), and to provide fuel for cooking and heating. People could no longer fish, make cloth, or build houses, so their diets became impoverished and they began to live in caves or reed huts. Deforestation also led to erosion, reducing soil fertility and crop yields. Chickens became the most important item in their diets, and the population was reduced to the miserable strategy of building stone chicken fortresses, which they defended in grotesque and bloody chicken wars. Cannibalism sometimes made up for lack of animal protein. Political structures broke down as the ceremonies surrounding statue construction could no longer be carried out. Indeed, the old traditions died out so thoroughly that two centuries later, the inhabitants had little idea of the past of their island or the significance of the statues. In short, population growth and increasing consumption of resources, driven by political and economic competition, led to sudden environmental and social collapse.

The most horrifying aspect of this story is that the islanders and their leaders must have seen it coming. They must have known as they felled the last trees that they were destroying their own future and that of their children. And yet they cut the trees down. Does Rapa Nui provide an appropriate parable for thinking about the larger trajectory of human history? After all, the creation of degraded environments after periods of rapid change, whether caused by megafaunal extinctions in the Stone Age or overirrigation in Mesopotamia in the third millennium BCE or in the Mayan lands just over a thousand years ago, has been a recurring theme in human history.

There are disturbing parallels between the trends described in the previous chapter and the history of Rapa Nui. As global inequalities increase, resources are being consumed in ever-increasing amounts to sustain the vast hierarchical structures of modern capitalist societies. Modern societies have their own forms of competitive monument building. Resources, from fresh water to timber, are being used faster than they can be replenished; and wastes, from plastics to carbon emissions, are being disposed of faster than they can be absorbed by natural ecological cycles. Yet populations continue to increase, and politicians the world over argue that economic growth must continue and even accelerate in order to alleviate the poverty of poorer countries and sustain the living standards of richer ones. But is growth really sustainable? If existing consumption levels are already dangerous, then the idea of a world in which the entire population consumes resources and produces wastes at the rate of the richer industrial nations is terrifying. Gandhi understood the problem as early as 1928, when he wrote: “God forbid that India should ever take to industrialism after the manner of the West… . If an entire nation of 300 million took to similar economic exploitation, it would strip the world bare like locusts.”7 Nevertheless, capitalism, now the dominant force in economic development, thrives on growth; and the political and business leaders who hold the greatest power today respond to the demands of local constituencies with short-term plans and projects, as did the statue-building chiefs of Rapa Nui. As on Rapa Nui, we appear incapable of stopping processes that threaten the future of our children and grandchildren.

But perhaps we can do better than the Easter Islanders.8 The most important reason for hope may be that collective learning now operates on a larger scale and more efficiently than ever before. If there are solutions to be found, both for humans and for the biosphere as a whole, the global information networks of modern humans can surely find them. These networks gave us the technologies that helped us mold the biosphere as we wished, and modern, electronically driven networks of collective learning have helped us understand the dangers of our increasing ecological power. In broad terms, the challenge is clear. To avoid a global replay of the catastrophes that overtook Easter Island, we must find more sustainable ways of living. We must use water, timber, energy, and raw materials at rates that can be supported for centuries, not decades; and we must produce waste products only in amounts that can be absorbed safely so we do not damage the environment and our fellow creatures. Can we do these things?

If populations keep growing at the rates typical of the late twentieth century, there is no hope. Here, though, we have reason for optimism, for global rates of population growth appear to be slowing, not only in the more affluent countries but also in some of the world’s poorer countries. The evidence for this demographic transition is now very strong. For most of the agrarian era, rates of population growth were governed by high birth rates and death rates; these encouraged parents to have many children, because they knew that some would die before adulthood. In the wealthier countries today, population growth is governed by a very different regime, dominated by lower death rates and birth rates and by improved welfare services. More children survive, and people expect to live longer; but because children are no longer the only source of support in old age, there is less need to have babies as a form of long-term insurance. The result is that birth rates have fallen, and population growth has declined—in some countries, to zero. The rapid population growth of recent decades and centuries was caused by a regime halfway between these two extremes, in which death rates fell (because of better medical care and increased food production), while birth rates remained high. The key to stabilizing global populations in the next century will be to reduce birth rates in the poorer countries, where they remain highest. The factors most likely to achieve this result are increased affluence, urbanization, improved infant health, and increased education, particularly of third world women (and particularly about contraception and health). Investment in improving health care and women’s education in poorer countries could have a dramatic impact on growth rates in the next few decades. Birth rates are already falling sharply in many poorer countries, so it is likely that sometime in the next century, global rates of population growth will stabilize. By 1998, thirty-three countries had zero population growth.9 The most optimistic estimates suggest that global populations will stabilize at about 9 to 10 billion. Feeding, clothing, and housing 3 or 4 billion more people will be a huge challenge, particularly as most will be born in the countries least able to provide for them; but given the rapid increases in food production in the twentieth century and the immense resources available in the richer countries, it should not be impossible. The graph in figure 15.2 suggests one likely scenario for population growth over the next century, in both richer and poorer countries.

Can consumption be similarly stabilized? To do so, we must take two crucial steps, both of which have begun to be implemented in small ways. The first is to shift from use of virgin resources to recycling. The second is to rely more heavily on sustainable and nonpolluting energy supplies. The necessary technologies already exist to exploit solar power, wind power, and fuel cells powered by hydrogen, though in present global markets (which do not factor in the environmental costs of different sources of energy) they cannot compete commercially with the fossil fuels that still power the Modern Revolution. But technologies for the cheap exchange of information are already with us as a result of the electronics revolution of the late twentieth century. In principle, we have the technologies needed to build a sustainable global economy without drastically reducing average living standards in the wealthier countries. But we may find, as in Rapa Nui, that the most difficult problems turn out to be political and educational rather than technological.





Figure 15.2. A modem “Malthusian cycle,” 1750–2100? This graph includes estimates of future population growth in both the developed and developing regions of the world. Today, most demographers are agreed that the rapid growth of the last two centuries will slow, and world populations should stabilize by the year 2100. But, as this graph shows, for a time, growth will continue in those regions least able to support larger populations. Adapted from Paul Kennedy, Preparing for the Twenty-First Century (London: Fontana, 1994), p. 23.



The political problems are indeed formidable. The political and business leaders who have the greatest power to make decisions on such issues are all accountable to particular regional or economic interest groups, and the workings of the political process encourage them to think on timescales too short to deal effectively with global ecological and social issues. They will be supported in their resistance to change by the affluent populations of the richer countries, for whom ecological crisis remains a distant and uncertain threat rather than the catastrophe it already is in many poorer countries. Besides, capitalism itself seems to depend on continued growth for its existence. Does this mean that capitalism must be overthrown? Sadly, the Communist revolutions of the twentieth century suggest that overthrowing capitalism may be an extremely destructive project, and one that is not in any case likely to create societies that are notably egalitarian or ecologically sensitive.

But politically, too, some indications are promising. One positive sign is the rapid emergence of a new global awareness of ecological issues and their interconnection with social and economic issues. Twenty years ago, few governments had ministries that specialized in environmental issues—now most governments take such issues seriously, and so do the electorates that choose them. The “Earth Summit”—the United Nations Conference on Environment and Development, held in Rio de Janeiro in 1992—was an important symbolic gesture toward sustainability, and it included a general agreement that the richer countries would have to help the poorer countries to develop in ways that were “environmentally sound.” For the first time, an international agreement argued that growth must be balanced against sustainability. Here, at least, was a rhetorical victory; a second conference followed, ten years later, in Johannesburg.

There have also been some examples of international cooperation, particularly on issues on which it has been easier to achieve a broad consensus. In the 1970s, evidence began to accumulate that the ozone layer was thinning because of the use of chlorofluorocarbons (CFCs).10 These were used in refrigeration, in air-conditioning, and as cleaners and solvents. In 1977, several developed nations urged UNEP (the United Nations Environment Program) to consider the issue, and a conference held that year adopted a plan for global action. At that point, no one took the issue seriously enough to act, in part because the scientific evidence remained ambiguous. In the early 1980s, the United States, which accounted for 30 percent of total emissions, took a leading position on reducing use of CFCs, partly because substitutes were available, and partly because of internal pressures from the emerging environmental lobby. But several other countries—including a number of countries in the European Community (EC), which produced 45 percent of global output—argued against regulation. Several developing countries, including China and India, also resisted regulation, as they were planning on increasing their production of CFCs. Clearly, an international agreement would be meaningless without the cooperation of these major current or potential producers. Some poorer countries maintained that they would need international funding to help them move away from dependence on CFCs. In the mid-1980s, the scientific evidence became clearer, and several “lead states” pushed for an international convention coupled with specific, binding protocols on the issue. In 1985, the Vienna Convention for the Protection of the Ozone Layer was signed, but it did little more than require international monitoring of CFC emissions. Then, at UNEP’s Montreal conference in 1987, under pressure from the lead states (including the United States), struggling with internal divisions, and facing superb negotiators, the EC agreed to a 50 percent cut by 1999. The Montreal Protocol on Substances That Deplete the Ozone Layer allowed developing countries to increase production for a time, but set caps on eventual output. Unfortunately, a veto by the United States and Japan kept money from being made available to help developing countries adjust. Within months, however, new scientific discoveries, including the discovery of a large hole in the ozone layer over the Antarctic, made the issue appear much more urgent. By May 1989, eighty nations had come out in support of the total elimination of CFCs by 2000. In 1990, a fund was created to help developing countries adjust, and thirty-two industrialized countries put about $1 billion into it. There are still loopholes in these agreements, but on the whole they have been extraordinarily successful. Production of CFCs fell from ca. 1.1 million tons in 1986 to 160,000 tons in 1996, and there is evidence that the hole in the ozone layer has started to shrink.

The international response to the ozone crisis shows that cooperation is possible. Nations, like individuals, can sometimes work together to solve common problems. And where evidence about the seriousness of a problem is clear, cooperation can be organized quickly and efficiently, even if it threatens some regional interests. The international mechanisms of cooperation that exist are clumsy and cumbersome, but they may be able to do the job in a crisis. The response to the thinning of the ozone layer is not the only example of their effectiveness, as Lester Brown points out: “Air pollution in Europe, for instance, has been reduced dramatically as a result of the 1979 treaty on transboundary air pollution. Global chlorofluorocarbon (CFC) emissions have dropped 60 per cent from their peak in 1988 following the 1987 treaty on ozone depletion and its subsequent amendments. The killing of elephants has plummeted in Africa because of the 1990 ban on commercial trade in ivory under the Convention on International Trade in Endangered Species of Wild Flora and Fauna.”11

But there is an even deeper problem. We have seen that capitalism is the driving force of innovation in the modern world, and capitalist economies depend on increasing production and sales. Is that growth incompatible with sustainability? The answer is unclear, but there are reasons for thinking that capitalism may well manage to coexist with at least some of the early stages of a transition to sustainability. One is that capitalist economies need increasing profits more than increasing production—and profits can be made in many ways, some of which are compatible with a sustainable economy. In principle, the recycling of resources or the sale of information and services rather than goods can generate profits as effectively as the exploitation of virgin resources. If governments were to start taxing unsustainable production methods more harshly, investment would soon move into more sustainable activities, where large profits could then be made. There is no absolute contradiction between capitalism and sustainability. Markets can be steered, as governments have known ever since John Maynard Keynes made this point in the 1930s. And some of the most effective methods of steering them include the use of taxes and subsidies to alter costs and direct economic activity in new directions. As Brown has argued forcefully, contemporary capitalism is ecologically destructive in part because it has no way of accounting for ecological values. For example, modern accounting methods cannot properly assess the services provided by forests in preventing floods, absorbing excess carbon dioxide, preventing soil erosion, and maintaining biodiversity. It is perfectly feasible, in principle, to use taxes and subsidies to build these costs into economic transactions. Indeed, governments routinely use these mechanisms today. An obvious example of how they could steer markets in more sustainable directions would be to introduce taxes on the use of fossil fuels—paid for, perhaps, by reductions in income taxes. Such taxes could transform the current balance of profitability between fossil fuels and less damaging energy sources such as wind power and fuel cells, because in a market economy, price signals can rapidly transform the behaviors of millions of consumers and producers.

But does the political will for taking such actions exist? For the answer to be “yes,” two things must happen: ecological dangers must become apparent to those who wield power in the modern world (governments can respond rapidly to crises once there is no doubt about their seriousness and magnitude), and popular attitudes, particularly in the richer countries, must change. Attitudes are critical. The widespread belief that continued growth in production is a good in itself poses one of the main barriers to reform. Such a belief will persist as long as good living is conceived in the ways we have been taught by consumer capitalism—as the never-ending consumption of more and better material goods. Changing definitions of what makes a good life may turn out to be one of the crucial steps toward a more sustainable relationship with the environment.

The other major challenges are ethical and political. Are the huge inequalities of the modern world tolerable? Will they not generate conflicts that guarantee the eventual use of the destructive military technologies now available to us? After all, the information networks of the modern world can disseminate knowledge about the manufacture of nuclear and biological weapons as well as about solar power cells. Thus it is a good bet that in the next few decades, more nations will have access to destructive weapons, and so will increasing numbers of guerrilla organizations such as al Qaeda that see themselves as defenders of the dispossessed and disempowered. Here, prediction is harder, because political changes are so dependent on the decisions and actions of individuals. Will the governments of wealthier countries decide that reducing global poverty can increase their own security? Perhaps forces less obvious but no less fundamental will encourage politicians to tackle the poverty of the world’s poorest countries. Capitalist economies need markets, and we have seen that consumer capitalism is distinguished from the system’s earlier forms by levels of productivity so high that it has to sell goods to its own workforce, to the subordinate classes that Marx called the proletariat. The same pressures will surely lead, eventually, to a rise in the living standards of subordinate classes in even the world’s poorest countries. And in this way, as global capitalism assumes less predatory forms, it may begin to raise living standards beyond the industrialized heartland. Thus, if a maturing world capitalist system can avoid the dangers of global overconsumption that Gandhi warned against, there is hope that even if relative inequalities continue to grow, the material living standards of subordinate classes in many other countries may be raised in the next century, generating new markets and reducing global political and military conflicts. Such a course of action might reduce the more abject forms of poverty, though inequality in general is bound to survive as long as capitalism remains the dominant shaper of economic change.

If some of the ecological and political problems of the twentieth century are genuinely addressed in this century, there is a chance that the gains of the Modern Revolution will be passed on to future generations. If not, there is a real danger that the Modern Revolution will spin out of control, causing military and ecological catastrophes that will leave our children and grandchildren a world as degraded as Easter Island, but with its devastation on a far larger scale.





THE MIDDLE FUTURE: THE NEXT CENTURIES AND MILLENNIA




When we think about more distant futures, say the next millennium or two, the open-endedness of historical change defeats us. Peter Stearns rightly describes “millennial forecasting” as a “nonstarter.”12 At this scale, alternative futures proliferate so fast that anything we say can be little more than guesswork. Besides, at the millennial scale, unlike the hundred-year scale, our capacity to shape the future also dwindles to insignificance, so we are under less pressure to predict.

It is easy to imagine catastrophic scenarios brought about by nuclear or biological warfare, or ecological disaster, or perhaps even a collision with a large asteroid. If caused by human action, such endings to human history might suggest that our species overreached itself, that what we think of today as progress was, in fact, the beginning of the end. Icarus will then seem the most appropriate metaphor for human ambition and creativity. It is almost as easy to imagine Utopian scenarios, in which most of the modern world’s problems are overcome—in which humans learn to construct ecologically sustainable economies, inequalities between different groups and regions have diminished significantly, and human technological prowess is used to provide a majority of the world’s population with a better life rather than with more and more material goods. Such an outcome would vindicate those who see human history as a story of progress.

But it is the in-between scenarios that are both most likely and most difficult to imagine. The best we can do here is to consider some of the larger trends shaping the modern world and assume that they will continue some way into the future.

If current demographic trends are sustained for a century or more, population growth will grind to a halt; human population numbers will stabilize or even decline, while average ages will rise. But another trend, technological innovation, shows no sign of slowing. There may well be eras of technological stagnation in the future, as there have been in the past, but the present burst of technological creativity seems set to continue, perhaps for a few centuries more. Stable populations and accelerating innovation in information technology, genetic engineering, and control of new energy sources (possibly including hydrogen fusion) ought to mean that increased productivity can be used not just to maintain minimum standards for ever-greater numbers of people but to raise the real living standards of everyone. Social and economic trends over the past 5,000 years offer little hope for a significant reduction in economic and political inequality. On the contrary, they suggest that gradients of wealth will get steeper, and the difference between the weakest and the most powerful will grow. But, as we have seen, the evolution of consumer capitalism during the past century indicates that the living standards of those at the bottom of these gradients may rise, if only because the poor are numerous enough to provide valuable markets for capitalist economies whose search for new consumers will become more frantic as populations stabilize while productivity keeps rising.

If environmental constraints do not bring the capitalist world system crashing down—if, instead, it manages to find new markets by selling to the poor as well as the rich, by seeking profits in ecologically sustainable production, and by trading more in services and information than in materials—then we can envisage further transformations generated by technologies we can only glimpse at present. Biotechnology may create new ways of feeding, clothing, and equipping a world of 10 to 12 billion people. It may also enable more and more of them to live longer and healthier lives. Nano-technology and new, faster microchips may surround us with intelligent robots of all sizes, some of which may behave in ways that are hard to distinguish from human intelligence. Meanwhile, new energy sources should increase the energy available to us. Finally, the space technologies envisioned by the Russian schoolteacher Konstantin Tsiolkovsky, which enabled the first human to leave Earth on 12 April 1961 and the first human to land on another heavenly body on 21 July 1969, will surely lead, eventually, to a new migratory phase in human history. In this phase, the networked world of today will be torn apart once more into separate regional webs. What makes such ideas more than science fiction is the knowledge that 500 years ago, no one had any idea of the speed and significance of the changes that would transform North America, a region of foragers and small-scale farming societies, into today’s superpower.

Colonization of other worlds may begin with the industrial exploitation of the Moon, nearby planets, and asteroids. It will continue with the planting of settlements on planets within our solar system. Both the industrial exploitation of asteroids and the initial colonization of Mars may be feasible within a century. More speculative (and more complex ethically) are plans for the “terraforming” of Mars—that is, the modification of Mars’s atmosphere and temperature to make it habitable for humans and other living organisms from Earth.13 Several plans of this kind already exist, though the changes they envisage could take a thousand years to complete. If they succeed, humans will have learned how to “domesticate” entire planets as they once domesticated large herbivores. Should humans start migrating from their home planet in larger numbers, the human history described so far in this book will eventually appear as merely the first chapter in a history, most of which will take place beyond the earth. In some ways, migrations to other planets will be reminiscent of the great migrations of the Stone Age that took members of our species into new environments within Africa, and then into the undiscovered lands of Australia, Siberia, and the Americas. Or perhaps a better analogy is with the great sea voyages that colonized the Pacific. But surviving beyond our earth will require all the technological ingenuity humans can muster. Migrants of the future will have to create entirely new ways of living, probably in totally artificial environments. And, like the Easter Islanders, they will not always succeed. Even on our nearest celestial neighbor, the Moon, they will live in a barren desert, enduring horrifying temperature extremes under a totally black sky.

Travel beyond our solar system is a different proposition, because of the huge distances involved and Einstein’s rule that nothing can travel faster than light.14 Light takes more than 4 years to travel to the nearest star, Proxima Centauri, while it takes almost 30,000 years to travel to the center of our own galaxy. And at present, we have no idea how to build a spaceship that could travel merely one-tenth of the speed of light, the lowest speed compatible with return journeys shorter than a human lifetime. As yet, even the most optimistic proposals do not envisage the making of such journeys for a few more centuries. Journeys of colonization, taken by travelers who, like Polynesian colonists, do not expect to return home, may be more realistic. These could rely on larger, slower spacecraft that would take hundreds of years to reach their destinations. Unlike Polynesian ships, “space arks” could become permanent homes, more comfortable and more attractive than any planets they might stumble across (see figure 15.3). Instead of traveling the universe as we do today, aboard naturally created planets whose movements we cannot control, humans of the future may travel in artificial planets that they can steer. In that case, the human future will lie not in the colonization of thousands of other planets but in the creation of thousands, even millions, of space arks, which periodically dip down to nearby planets to replenish stocks of fuel and raw materials. It has been estimated that successive waves of interstellar colonizers, traveling at relatively low speeds, could take a hundred million years to reach the most distant parts of our own galaxy; our existing knowledge barely enables us to begin to visualize journeys to other galaxies. But even space arks will not be built in the near future.

If humans do begin to travel beyond our solar system, there may again emerge a human society broken into separate worlds, like the many societies of the Pacific, each with its own distinctive history, for contact will be intermittent and slow. According to Arthur C. Clarke, “The finite velocity of light will, inevitably, divide the human race once more into scattered communities, sundered by barriers of space and time. We will be one with our remote ancestors, who lived in a world of immense and often insuperable distances, for we are moving out into a universe vaster than all their dreams.”15 If the separation lasts for long enough, the networks that have linked humans for most of their history will fray. The cultural networks will snap first, but then the genetic links that define modern humans as a single species will thin and at some points break. Humans, like the finches of the Galápagos Islands, will start to evolve into innumerable separate and diverging species, each adjusted to a particular local environment.





Figure 15.3. A possible design for a space colony: a future for humans in the cosmos? Is this how a majority of humans will live in two or three centuries from now? Will humans repeat the epic migrations of the Paleolithic era, but now on the scale of the solar system, or even in interstellar space? This illustration is based on ideas for a space colony to explore the solar system developed by the Princeton physicist Gerard K. O’Neill in the 1970s and 1980s. Each cylinder would be up to 30 kilometers long, and could contain populations of thousands, or hundreds of thousands, of people. Each of the three strips (“countries”?) would enjoy daylight for one-third of the colony’s “day.” Adapted from Nikos Prantzos, Our Cosmic Future: Humanity’s Fate in the University (Cambridge: Cambridge University Press, 2000), p. 42.



Evolutionary change is unavoidable, whether or not humans colonize other worlds. Few mammal species last more than a few million years without evolving into new species. Humans count as a young species, with a potential future of hundreds of thousands or perhaps even a few million years. But modern genetic technologies may soon enable humans to start consciously manipulating their own genetic makeup. With the decoding of the human genome at the end of the twentieth century, we already know the blueprint on which humans are constructed, even if we do not yet understand all the intricate ways in which different parts of that blueprint interact with each other. It is thus likely that in the next few centuries, humans will begin to engineer their own bodies, without waiting for the slower processes of natural selection to do their work.16 Will it make sense any longer to think of these people as us or as our descendants?

And will these descendants ever meet other intelligent, networked beings? There are good reasons to think they will not, at least not within our own galaxy. Observations of planets orbiting nearby stars and discoveries of living organisms in what were once thought to be impossibly harsh environments—in volcanic vents in the sea, and frozen deep within rocks—both suggest that life may be common, at least where stars and planets exist. Moreover, the speed with which the first life-forms appeared on Earth indicates that life can form rapidly where the conditions are right. But intelligent life-forms that can share information as humans do may be extraordinarily rare. It took 4 billion years to evolve networked, large-brained creatures on this earth, and that was a chancy business and could easily have taken longer; the evolutionary pathways leading to large brains seem to be extraordinarily narrow. There thus is no certainty that anything like our species would evolve even after huge periods of time. Besides, if intelligent, information-sharing creatures were common, the absence of any clear evidence for their existence would be puzzling. On a visit to Los Alamos in 1950, the physicist Enrico Fermi put this argument in the form of a simple question: “But where are they?” If such species were common, then there should be many intelligent, networked communities with technologies much more advanced than ours, and we should have come across signals of some kind from some of them.17 If humans ever reach planets near other stars, they may find, like Polynesian travelers who made their way across the Pacific, that there are no other creatures as complex or technologically sophisticated as themselves.

But at this point we are moving into pure speculation, as is inevitable when we make any guesses about the nature of human societies in a thousand years’ time. We can remind ourselves how speculative such ideas may be by remembering that the dinosaurs, as a group, appeared to be flourishing before they were destroyed in a geological instant by an asteroid impact 65 million years ago.





THE REMOTE FUTURE: THE FUTURE OF THE SOLAR SYSTEM, THE GALAXY, AND THE UNIVERSE




Oddly, the obscurity lifts at the largest scales, for astronomers deal with larger but simpler objects than historians, objects that change very slowly over huge time periods. Astronomers are confident that they have a good idea of what is in store for planets and stars, and even for the universe itself.

The ultimate fate of the biosphere will be determined by the evolution of the earth and its sun. Though these are large systems, they are simpler than the biosphere or human society, so their future evolution is more predictable. Our sun is about halfway through its life cycle, giving it another 4 billion or so years to live. But life on Earth will die out well before the Sun dies. As it ages, the Sun will heat up until eventually the surface of Earth begins to heat up, too. The biosphere may evolve in ways that slow the impact of these changes, but eventually those organisms still living on Earth will run out of options. In 3 billion years’ time, Earth will receive as much heat from the Sun as Venus does today; the oceans will boil, and their steam will contribute to massive global warming. Earth will become uninhabitable.18 Eventually, it will be as barren as the Moon is today.

When the Sun burns up all its hydrogen, it will become unstable. It will eject material from its outer layers, and its inner core, freed from the pressure of these outer layers, will expand until it reaches where the earth is now. However, the Sun’s reduced mass and gravitational pull will allow the earth to drift out to a more distant orbit, 60 million kilometers away. Nikos Prantzos describes the resulting view from Earth: “If an observer could survive the fiery furnace on its surface, at temperatures approaching 2000° C, he or she would see a sight worthy of Dante’s inferno. The Sun’s disk would occupy more than three quarters of the sky.”19 If anyone is watching as the Sun engulfs our earth, they may be visitors from farther out in the solar system; for a time, the moons of Jupiter and Saturn, such as Titan and Europa, may become habitable. Then the Sun will shrink once more, as it starts to burn helium in its core, but only for about 100 million years. When it runs out of helium, it will flare up again and start manufacturing oxygen and carbon. At this stage, even the outer planets will become uninhabitable. Then, the furnaces at the center of the Sun will finally die down and it will shrink into a white dwarf: an extremely dense, brilliantly hot mass of material that, because it has no internal heat engine, will gradually cool and darken during an afterlife lasting many times longer than its fusion phase.

The hundreds of billions of stars in the Milky Way will not notice its passing—though perhaps they should, for it will offer a small portent of the galaxy’s distant future. About 90 percent of the material from which stars can be manufactured has already been used, so the era of star formation is drawing to a close. In just a few tens of billions of years from now, star formation will cease; then, when the surviving stars start dying, the lights will dim and begin to go out. In a cold, dark universe, energy gradients will no longer be steep enough to create complex entities; the universe will become simpler and simpler, and the second law of thermodynamics will assert its bleak authority more and more effectively. But this will not happen quickly, and not without reverses: the smaller stars, like remnants of a once-powerful guerrilla army, will live for many times the age of the existing universe. Then, a few thousand billion years from now, even they will shut down, and the universe will be dark again, as it was in its early days. But now it will be like a huge cosmic junkyard, full of cold, dark objects such as brown dwarfs, dead planets, asteroids, neutron stars, and black holes.20

And what will happen next? We do not know for sure, but we know some of the likely scripts. The future depends largely on the balance between expansion, which drives the universe apart, and the force of gravity, which draws it together. If there is enough mass/energy to slow the expansion of the universe to a halt, then, after perhaps a few thousand billion years, the universe must start contracting. The contraction phase will not be a mere reversal of the expansion phase, as some once believed. It was even supposed at one time that “big crunches” might be followed by new big bangs, in a scenario of bouncing universes that some saw as a modern version of cyclical cosmologies, such as those of the Maya.21 Such ideas encouraged astronomers to attempt a detailed census of the amount of matter/energy in the universe. At first it seemed that there was far too little matter to halt the expansion of the universe, but it gradually became clear that there is a huge amount of matter or energy that we cannot see. And, as various indirect methods were used to estimate the amount of dark matter, it began to appear that gravity and expansion were extraordinarily finely balanced, making the universe’s ultimate fate uncertain. In the late 1990s, however, the discovery of so-called vacuum energy offered a resolution to these debates—in part because the vacuum energy could itself account for much of the missing matter/energy, and in part because it seemed to guarantee that the expansion of the universe would not slow but would instead increase, for vacuum energy appears to be gently accelerating the rate at which the universe expands.

Currently, most astrophysicists believe that the universe will keep expanding forever. It is, in their jargon, “open” rather than “closed.” As it gets bigger, the spaces between galaxies will increase, and the universe will get simpler, colder, and lonelier in an infinitely slow diminuendo. The good times will be over for good. With the reduction in temperature difference between hot and cold objects, entropy will increase, making the formation of complex entities increasingly difficult, though the continued expansion of the universe will ensure that it never reaches a state of perfect thermodynamic equilibrium. As the universe ages, light will come only from rare flare-ups, as cold lumps of matter collide randomly to form a few new stars. These lonely beacons of light will find themselves in a colossal galactic graveyard, surrounded by billions of stellar corpses. Gravitational forces will push some of the corpses out into empty space, where each will endure a lonely purgatory as it travels farther and farther away from anything else, until finally it perishes in its own private universe. Those star corpses that stay within the former galaxies will be pulled together by gravity until they merge into huge galactic black holes. Any matter left outside them will also begin to decay if (as some modern theories suggest) even protons are not forever. From perhaps 1030 years after the big bang onward, the universe will be a dark, cold place, filled only with black holes and stray subatomic particles that wander light-years apart from each other.

But as Stephen Hawking showed in the early 1970s, even black holes lose energy, and over unimaginable periods of time they, too, will disappear. Their deaths by quantum evaporation will last billions of times longer than all the eras that passed before, so long that each billion years will count as no more than a single grain of sand on an earthly beach (see table 15.1). On these scales, according to Prantzos, the 1030 years before black holes began to dominate the universe “will look even shorter than the Planck time does for us today!”22 What will the dying black holes leave behind? Very little: Paul Davies imagines “an inconceivably dilute soup of photons, neutrinos, and a dwindling number of electrons and positrons, all slowly moving farther and farther apart. As far as we know, no further basic physical processes would ever happen. No significant event would occur to interrupt the bleak sterility of a universe that has run its course yet still faces eternal life—perhaps eternal death would be a better description.”23

To an imaginary observer watching the death agony of the last black holes, the few billion years considered in this book will seem like a dazzling flash of creativity at the beginning of time, a split second in which huge and chaotic energies challenged the second law of thermodynamics and conjured up the menagerie of exotic and complex entities that make up our world. In that fleeting springtime, before it cooled and darkened, the universe was bursting with creativity. And in at least one obscure galaxy, there appeared a networked, intelligent species capable of contemplating the universe as a whole and of reconstructing much of its past.24

It is tempting to think that this flash of creativity was laid on for humans—the ultimate justification, perhaps, for the universe’s creation from nothing. Modern science offers no good reason for believing in such anthropocentrism. Instead, it seems, we are one of the more exotic creations of a universe in the most youthful, exuberant, and productive phase of a very long life. Though we no longer see ourselves as the center of the universe or the ultimate reason for its existence, this may still be grandeur enough for many of us.

TABLE 15.1. A CHRONOLOGY OF THE COSMIC FUTURE IN AN OPEN UNIVERSE





Time Since Big Bang

(years)

Significant Events



1014



Most Stars are dead; the Universe is dominated by cold objects, black dwarfs, neutron stars, dead planets/asteroids, and stellar black holes; surviving matter is isolated as universe keeps expanding.





1020



Many objects have drifted away from galaxies; those remaining have collapsed into galactic black holes.





1032



protons have largely decayed, leaving a universe of energy, leptons, and black holes.





1066–10106



Stellar and galactic black holes evaporate.





101500



Through quantum “tunneling,” remaining matter is transformed into iron.





101076



Remaining matter is transformed into neutronic matter, then into black holes, which evaporate.





SOURCES: Adapted from Nikos Prantzos, Our Cosmic Future: Humanity’s Fate in the Universe (Cambridge: Cambridge University Press, 2000), p. 263.





SUMMARY




Predicting the future is a chancy business, because the universe is inherently unpredictable. But in some situations we have to try. It is worth thinking hard about the next century, because what we do today may have a significant impact on the lives of those who live a century from now. If our predictions are not too far from the mark, and we act intelligently in the light of those predictions, we may be able to avoid disaster. Such disasters could take several forms, including severe ecological degradation and military conflicts generated by growing inequalities in access to resources. The two issues are linked; and, with intelligent management, it may be possible to steer the world toward a more sustainable relationship with the environment and create a global economy that raises the living conditions of the poor, even if it remains biased toward the wealthy. On scales of several centuries, the possibilities multiply so rapidly that it is hardly worth the effort of trying to make predictions. But there are large trends, particularly in technology, that may hint at some plausible futures. Humans may migrate to planets or moons within the solar system, and perhaps even farther afield; and they may learn to control genetic processes with great precision. But any particular predictions could, of course, be derailed by unexpected crises, whether caused by humans or by geological or astronomical phenomena such as asteroid impacts. At cosmological scales, our predictions become more confident once again. The Sun and our solar system will die within 4 billion years, but the universe will survive much longer. Recent evidence suggests that the expansion of the universe will continue forever. If this is so, then we can use contemporary understanding of fundamental physical and astronomical processes to describe how, as the universe keeps expanding, it will also decay. From the standpoint of an inconceivably distant future, when the universe contains no more than a depressingly thin sprinkling of photons and subatomic particles, the 13 billion years covered in this book will seem like a brief, exuberant springtime.





FURTHER READING




Peter Stearns, Millennium III, Century XXI (1996), discusses the history of futurology; and Yorick Blumenfeld, ed., Scanning the Future (1999), brings together some essays on futurology. In Signs of Life (2000), Ricard Solé and Brian Goodwin offer a good discussion of the problems of prediction and the nature of unpredictability. On the ecological future, some of the most accessible works are Lester Brown, Eco-Economy (2001) (though it has been subjected to a tough statistical critique in Bjørn Lomborg, The Skeptical Environmentalist [2001]), and Paul Kennedy, Preparing for the Twenty-First Century (1994). The middle future is best represented in works of fiction. Brian Stableford and David Langford’s The Third Millennium (1985) is a fascinating and moderately optimistic “history” of the next thousand years, while Walter Miller’s A Canticle for Leibowitz (1959), written at the height of the cold war, portrays a future in which human creativity and rationality lead only to periodic nuclear holocausts. On even larger scales, science comes into its own again. Nikos Prantzos, Our Cosmic Future (2000), discusses possibilities for space travel, and also explores the most remote cosmological futures, as does Paul Davies, The Last Three Minutes (1995).